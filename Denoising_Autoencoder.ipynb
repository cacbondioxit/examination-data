{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Denoising Autoencoder.ipynb",
      "provenance": [],
      "mount_file_id": "1R9d7Og7GrMDO6YXrQKW-ho0WhsL3h7_v",
      "authorship_tag": "ABX9TyMyByjsgZPjW1WEkcNgfDw/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cacbondioxit/examination-data/blob/main/Denoising_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H2SX7iK4bWvH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/전력사용량(기출2).txt', sep=\"\\t\", encoding='cp949', header=0)"
      ],
      "metadata": {
        "id": "Sf8RoiT8dQkb"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9Pxa9esgeR51",
        "outputId": "8207d069-29ff-4fa6-fdc3-7cf43865030e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      ID BUILD  REGION  FAMILY  ROOM  HOUSE  POWER  REF  BYEAR  LIGHT  TV  \\\n",
              "0      1   아파트       1       4     4      3    345    2   2012      6   3   \n",
              "1      2   아파트       3       3     2      2    211    1   2000      3   1   \n",
              "2      3   다세대       2       2     2      1    135    1   2005      3   1   \n",
              "3      4    단독       3       3     3      2    257    2   1000      5   2   \n",
              "4      5    연립       1       5     3      3    323    2   2004      8   2   \n",
              "..   ...   ...     ...     ...   ...    ...    ...  ...    ...    ...  ..   \n",
              "439  440   아파트       1       6     3      3    343    2   2010     11   3   \n",
              "440  441   다세대       3       4     3      2    287    2   2000      9   2   \n",
              "441  442    단독       1       2     2      1    187    1   2011      4   1   \n",
              "442  443   아파트       3       5     3      3    301    3   1998     12   3   \n",
              "443  444   아파트       2       2     2      1    178    1   2003      5   1   \n",
              "\n",
              "     AREA  \n",
              "0      21  \n",
              "1      18  \n",
              "2      25  \n",
              "3      24  \n",
              "4      29  \n",
              "..    ...  \n",
              "439    31  \n",
              "440    29  \n",
              "441    16  \n",
              "442    32  \n",
              "443    20  \n",
              "\n",
              "[444 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-960f6556-f17f-41e0-b148-76f1185efb8d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>BUILD</th>\n",
              "      <th>REGION</th>\n",
              "      <th>FAMILY</th>\n",
              "      <th>ROOM</th>\n",
              "      <th>HOUSE</th>\n",
              "      <th>POWER</th>\n",
              "      <th>REF</th>\n",
              "      <th>BYEAR</th>\n",
              "      <th>LIGHT</th>\n",
              "      <th>TV</th>\n",
              "      <th>AREA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>아파트</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>345</td>\n",
              "      <td>2</td>\n",
              "      <td>2012</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>아파트</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>1</td>\n",
              "      <td>2000</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>다세대</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>135</td>\n",
              "      <td>1</td>\n",
              "      <td>2005</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>단독</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>257</td>\n",
              "      <td>2</td>\n",
              "      <td>1000</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>연립</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>323</td>\n",
              "      <td>2</td>\n",
              "      <td>2004</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>440</td>\n",
              "      <td>아파트</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>343</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>441</td>\n",
              "      <td>다세대</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>287</td>\n",
              "      <td>2</td>\n",
              "      <td>2000</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>442</td>\n",
              "      <td>단독</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>442</th>\n",
              "      <td>443</td>\n",
              "      <td>아파트</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>1998</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443</th>\n",
              "      <td>444</td>\n",
              "      <td>아파트</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>1</td>\n",
              "      <td>2003</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>444 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-960f6556-f17f-41e0-b148-76f1185efb8d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-960f6556-f17f-41e0-b148-76f1185efb8d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-960f6556-f17f-41e0-b148-76f1185efb8d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['BUILD'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLNhWnO_gg0P",
        "outputId": "3cb43a20-6ca5-4f82-e271-8fe93e84d484"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['아파트', '다세대', '단독', '연립'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(str):\n",
        "    if str == '아파트': return 1\n",
        "    if str == \"다세대\": return 2\n",
        "    if str == \"단독\": return 3\n",
        "    if str == \"연립\": return 4"
      ],
      "metadata": {
        "id": "EiiknnciglAU"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(data)):\n",
        "    temp = data.loc[i, 'BUILD']\n",
        "    data.loc[i, 'BUILD'] = encode(temp)"
      ],
      "metadata": {
        "id": "bllyBMPietWM"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "3mkFBsNXheIe",
        "outputId": "55f9c58b-f63d-4b0f-938b-ac95995bcabd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      ID BUILD  REGION  FAMILY  ROOM  HOUSE  POWER  REF  BYEAR  LIGHT  TV  \\\n",
              "0      1     1       1       4     4      3    345    2   2012      6   3   \n",
              "1      2     1       3       3     2      2    211    1   2000      3   1   \n",
              "2      3     2       2       2     2      1    135    1   2005      3   1   \n",
              "3      4     3       3       3     3      2    257    2   1000      5   2   \n",
              "4      5     4       1       5     3      3    323    2   2004      8   2   \n",
              "..   ...   ...     ...     ...   ...    ...    ...  ...    ...    ...  ..   \n",
              "439  440     1       1       6     3      3    343    2   2010     11   3   \n",
              "440  441     2       3       4     3      2    287    2   2000      9   2   \n",
              "441  442     3       1       2     2      1    187    1   2011      4   1   \n",
              "442  443     1       3       5     3      3    301    3   1998     12   3   \n",
              "443  444     1       2       2     2      1    178    1   2003      5   1   \n",
              "\n",
              "     AREA  \n",
              "0      21  \n",
              "1      18  \n",
              "2      25  \n",
              "3      24  \n",
              "4      29  \n",
              "..    ...  \n",
              "439    31  \n",
              "440    29  \n",
              "441    16  \n",
              "442    32  \n",
              "443    20  \n",
              "\n",
              "[444 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d067ea86-2a63-4b16-bdd2-ca8df2a0a80f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>BUILD</th>\n",
              "      <th>REGION</th>\n",
              "      <th>FAMILY</th>\n",
              "      <th>ROOM</th>\n",
              "      <th>HOUSE</th>\n",
              "      <th>POWER</th>\n",
              "      <th>REF</th>\n",
              "      <th>BYEAR</th>\n",
              "      <th>LIGHT</th>\n",
              "      <th>TV</th>\n",
              "      <th>AREA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>345</td>\n",
              "      <td>2</td>\n",
              "      <td>2012</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>1</td>\n",
              "      <td>2000</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>135</td>\n",
              "      <td>1</td>\n",
              "      <td>2005</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>257</td>\n",
              "      <td>2</td>\n",
              "      <td>1000</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>323</td>\n",
              "      <td>2</td>\n",
              "      <td>2004</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>440</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>343</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>441</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>287</td>\n",
              "      <td>2</td>\n",
              "      <td>2000</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>442</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>442</th>\n",
              "      <td>443</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>1998</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443</th>\n",
              "      <td>444</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>1</td>\n",
              "      <td>2003</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>444 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d067ea86-2a63-4b16-bdd2-ca8df2a0a80f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d067ea86-2a63-4b16-bdd2-ca8df2a0a80f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d067ea86-2a63-4b16-bdd2-ca8df2a0a80f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wgXl6O6ogcu",
        "outputId": "53c85c77-dd19-4835-de8f-4dd4c236dbec"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID         int64\n",
              "BUILD     object\n",
              "REGION     int64\n",
              "FAMILY     int64\n",
              "ROOM       int64\n",
              "HOUSE      int64\n",
              "POWER      int64\n",
              "REF        int64\n",
              "BYEAR      int64\n",
              "LIGHT      int64\n",
              "TV         int64\n",
              "AREA       int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"BUILD\"] = pd.to_numeric(data[\"BUILD\"])"
      ],
      "metadata": {
        "id": "jPTRbcQuow7w"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6cPJSM4o9IF",
        "outputId": "3c30db28-4b9c-4182-cba0-4b887971c966"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID        int64\n",
              "BUILD     int64\n",
              "REGION    int64\n",
              "FAMILY    int64\n",
              "ROOM      int64\n",
              "HOUSE     int64\n",
              "POWER     int64\n",
              "REF       int64\n",
              "BYEAR     int64\n",
              "LIGHT     int64\n",
              "TV        int64\n",
              "AREA      int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = data.copy()"
      ],
      "metadata": {
        "id": "rLcJF0mae7sF"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "trk87UxzhlCP",
        "outputId": "51584ac9-ef05-47dd-ae37-aa2a1b551887"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      ID  BUILD  REGION  FAMILY  ROOM  HOUSE  POWER  REF  BYEAR  LIGHT  TV  \\\n",
              "0      1      1       1       4     4      3    345    2   2012      6   3   \n",
              "1      2      1       3       3     2      2    211    1   2000      3   1   \n",
              "2      3      2       2       2     2      1    135    1   2005      3   1   \n",
              "3      4      3       3       3     3      2    257    2   1000      5   2   \n",
              "4      5      4       1       5     3      3    323    2   2004      8   2   \n",
              "..   ...    ...     ...     ...   ...    ...    ...  ...    ...    ...  ..   \n",
              "439  440      1       1       6     3      3    343    2   2010     11   3   \n",
              "440  441      2       3       4     3      2    287    2   2000      9   2   \n",
              "441  442      3       1       2     2      1    187    1   2011      4   1   \n",
              "442  443      1       3       5     3      3    301    3   1998     12   3   \n",
              "443  444      1       2       2     2      1    178    1   2003      5   1   \n",
              "\n",
              "     AREA  \n",
              "0      21  \n",
              "1      18  \n",
              "2      25  \n",
              "3      24  \n",
              "4      29  \n",
              "..    ...  \n",
              "439    31  \n",
              "440    29  \n",
              "441    16  \n",
              "442    32  \n",
              "443    20  \n",
              "\n",
              "[444 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a7bf5d5-12ed-4fcc-8d4a-46885f39f518\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>BUILD</th>\n",
              "      <th>REGION</th>\n",
              "      <th>FAMILY</th>\n",
              "      <th>ROOM</th>\n",
              "      <th>HOUSE</th>\n",
              "      <th>POWER</th>\n",
              "      <th>REF</th>\n",
              "      <th>BYEAR</th>\n",
              "      <th>LIGHT</th>\n",
              "      <th>TV</th>\n",
              "      <th>AREA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>345</td>\n",
              "      <td>2</td>\n",
              "      <td>2012</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>1</td>\n",
              "      <td>2000</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>135</td>\n",
              "      <td>1</td>\n",
              "      <td>2005</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>257</td>\n",
              "      <td>2</td>\n",
              "      <td>1000</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>323</td>\n",
              "      <td>2</td>\n",
              "      <td>2004</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>440</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>343</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>441</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>287</td>\n",
              "      <td>2</td>\n",
              "      <td>2000</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>442</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>442</th>\n",
              "      <td>443</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>1998</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443</th>\n",
              "      <td>444</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>1</td>\n",
              "      <td>2003</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>444 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a7bf5d5-12ed-4fcc-8d4a-46885f39f518')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a7bf5d5-12ed-4fcc-8d4a-46885f39f518 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a7bf5d5-12ed-4fcc-8d4a-46885f39f518');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data2[data2['REGION']==9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "ER9lkHk_hmzc",
        "outputId": "b37a0d0b-ab13-4862-d49c-bd35b01f3a8a"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      ID  BUILD  REGION  FAMILY  ROOM  HOUSE  POWER  REF  BYEAR  LIGHT  TV  \\\n",
              "274  275      2       9       3     2      2    200    1   2001      6   1   \n",
              "313  314      1       9       2     2      1    178    1   2003      5   1   \n",
              "\n",
              "     AREA  \n",
              "274    24  \n",
              "313    21  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86bb5565-ea99-4698-807d-cf0051c19b1f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>BUILD</th>\n",
              "      <th>REGION</th>\n",
              "      <th>FAMILY</th>\n",
              "      <th>ROOM</th>\n",
              "      <th>HOUSE</th>\n",
              "      <th>POWER</th>\n",
              "      <th>REF</th>\n",
              "      <th>BYEAR</th>\n",
              "      <th>LIGHT</th>\n",
              "      <th>TV</th>\n",
              "      <th>AREA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>275</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>200</td>\n",
              "      <td>1</td>\n",
              "      <td>2001</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>314</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>1</td>\n",
              "      <td>2003</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86bb5565-ea99-4698-807d-cf0051c19b1f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86bb5565-ea99-4698-807d-cf0051c19b1f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86bb5565-ea99-4698-807d-cf0051c19b1f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = data2.drop(\"ID\", axis=1)"
      ],
      "metadata": {
        "id": "FhnoI06xiQUE"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeO3SneGoMCV",
        "outputId": "680597b5-0b8a-4b2b-cafa-64821fc5a5b7"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BUILD     int64\n",
              "REGION    int64\n",
              "FAMILY    int64\n",
              "ROOM      int64\n",
              "HOUSE     int64\n",
              "POWER     int64\n",
              "REF       int64\n",
              "BYEAR     int64\n",
              "LIGHT     int64\n",
              "TV        int64\n",
              "AREA      int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data2.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_Lk39cFiYg_",
        "outputId": "79683182-f85a-43c2-fcbf-80d8fa6a27bb"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def noise(array):\n",
        "#     \"\"\"\n",
        "#     Adds random noise to each image in the supplied array.\n",
        "#     \"\"\"\n",
        "\n",
        "#     noise_factor = 0.4\n",
        "#     noisy_array = array + noise_factor * np.random.normal(\n",
        "#         loc=0.0, scale=1.0, size=array.shape\n",
        "#     )\n",
        "\n",
        "#     return np.clip(noisy_array, 0.0, 1.0)\n",
        "\n",
        "\n",
        "# def display(array1, array2):\n",
        "#     \"\"\"\n",
        "#     Displays ten random images from each one of the supplied arrays.\n",
        "#     \"\"\"\n",
        "\n",
        "#     n = 10\n",
        "\n",
        "#     indices = np.random.randint(len(array1), size=n)\n",
        "#     images1 = array1[indices, :]\n",
        "#     images2 = array2[indices, :]\n",
        "\n",
        "#     plt.figure(figsize=(20, 4))\n",
        "#     for i, (image1, image2) in enumerate(zip(images1, images2)):\n",
        "#         ax = plt.subplot(2, n, i + 1)\n",
        "#         plt.imshow(image1.reshape(28, 28))\n",
        "#         plt.gray()\n",
        "#         ax.get_xaxis().set_visible(False)\n",
        "#         ax.get_yaxis().set_visible(False)\n",
        "\n",
        "#         ax = plt.subplot(2, n, i + 1 + n)\n",
        "#         plt.imshow(image2.reshape(28, 28))\n",
        "#         plt.gray()\n",
        "#         ax.get_xaxis().set_visible(False)\n",
        "#         ax.get_yaxis().set_visible(False)\n",
        "\n",
        "#     plt.show()"
      ],
      "metadata": {
        "id": "-sx1OdX5beNC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = layers.Input(shape=(len(data2.columns), ))\n",
        "\n",
        "# Encoder\n",
        "x = layers.Dense(8, activation=\"relu\")(input)\n",
        "x = layers.Dense(6, activation=\"relu\")(x)\n",
        "x = layers.Dense(4, activation=\"relu\")(x)\n",
        "\n",
        "# Decoder\n",
        "x = layers.Dense(6, activation=\"relu\")(x)\n",
        "x = layers.Dense(8, activation=\"relu\")(x)\n",
        "x = layers.Dense(len(data2.columns), activation=\"relu\")(input)\n",
        "\n",
        "# Autoencoder\n",
        "autoencoder = Model(input, x)\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
        "autoencoder.compile(optimizer=optimizer, loss=\"mse\")\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILAXLMiZbm-M",
        "outputId": "96eec055-53b9-4194-a8fb-d6c7ea3f4653"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 11)]              0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 11)                132       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 132\n",
            "Trainable params: 132\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(x):\n",
        "    return (x-np.mean(x))/(np.std(x))"
      ],
      "metadata": {
        "id": "BOjr24TZxICL"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2['POWER'] = normalize(data2['POWER'])"
      ],
      "metadata": {
        "id": "X0Tht3ySxWkw"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2['BYEAR'] = normalize(data2['BYEAR'])"
      ],
      "metadata": {
        "id": "753wHRcSxe-c"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2['AREA'] = normalize(data2['AREA'])"
      ],
      "metadata": {
        "id": "2qB1eAeuxiC3"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OnjlGW6exc2g",
        "outputId": "b8a63973-f673-42d0-c321-096483e29e95"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     BUILD  REGION  FAMILY  ROOM  HOUSE     POWER  REF     BYEAR  LIGHT  TV  \\\n",
              "0        1       1       4     4      3  1.218074    2  0.068442      6   3   \n",
              "1        1       3       3     2      2 -0.647800    1  0.040497      3   1   \n",
              "2        2       2       2     2      1 -1.706056    1  0.052141      3   1   \n",
              "3        3       3       3     3      2 -0.007276    2 -2.288296      5   2   \n",
              "4        4       1       5     3      3  0.911737    2  0.049812      8   2   \n",
              "..     ...     ...     ...   ...    ...       ...  ...       ...    ...  ..   \n",
              "439      1       1       6     3      3  1.190225    2  0.063785     11   3   \n",
              "440      2       3       4     3      2  0.410457    2  0.040497      9   2   \n",
              "441      3       1       2     2      1 -0.981986    1  0.066114      4   1   \n",
              "442      1       3       5     3      3  0.605399    3  0.035839     12   3   \n",
              "443      1       2       2     2      1 -1.107306    1  0.047483      5   1   \n",
              "\n",
              "         AREA  \n",
              "0   -0.056200  \n",
              "1   -0.062545  \n",
              "2   -0.047741  \n",
              "3   -0.049856  \n",
              "4   -0.039281  \n",
              "..        ...  \n",
              "439 -0.035052  \n",
              "440 -0.039281  \n",
              "441 -0.066774  \n",
              "442 -0.032937  \n",
              "443 -0.058315  \n",
              "\n",
              "[444 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19790e3d-176a-4b83-b16a-b1ec4060d787\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BUILD</th>\n",
              "      <th>REGION</th>\n",
              "      <th>FAMILY</th>\n",
              "      <th>ROOM</th>\n",
              "      <th>HOUSE</th>\n",
              "      <th>POWER</th>\n",
              "      <th>REF</th>\n",
              "      <th>BYEAR</th>\n",
              "      <th>LIGHT</th>\n",
              "      <th>TV</th>\n",
              "      <th>AREA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1.218074</td>\n",
              "      <td>2</td>\n",
              "      <td>0.068442</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.056200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.647800</td>\n",
              "      <td>1</td>\n",
              "      <td>0.040497</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.062545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.706056</td>\n",
              "      <td>1</td>\n",
              "      <td>0.052141</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.047741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.007276</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.288296</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.049856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.911737</td>\n",
              "      <td>2</td>\n",
              "      <td>0.049812</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.039281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1.190225</td>\n",
              "      <td>2</td>\n",
              "      <td>0.063785</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.035052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.410457</td>\n",
              "      <td>2</td>\n",
              "      <td>0.040497</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.039281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.981986</td>\n",
              "      <td>1</td>\n",
              "      <td>0.066114</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.066774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>442</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.605399</td>\n",
              "      <td>3</td>\n",
              "      <td>0.035839</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.032937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.107306</td>\n",
              "      <td>1</td>\n",
              "      <td>0.047483</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.058315</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>444 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19790e3d-176a-4b83-b16a-b1ec4060d787')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19790e3d-176a-4b83-b16a-b1ec4060d787 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19790e3d-176a-4b83-b16a-b1ec4060d787');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test = train_test_split(data2, shuffle=False)"
      ],
      "metadata": {
        "id": "q4fL4VbnjbO2"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "t9YFvSxyq2gj",
        "outputId": "761afe58-b870-4a25-c85b-32073a254436"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     BUILD  REGION  FAMILY  ROOM  HOUSE     POWER  REF     BYEAR  LIGHT  TV  \\\n",
              "0        1       1       4     4      3  1.218074    2  0.068442      6   3   \n",
              "1        1       3       3     2      2 -0.647800    1  0.040497      3   1   \n",
              "2        2       2       2     2      1 -1.706056    1  0.052141      3   1   \n",
              "3        3       3       3     3      2 -0.007276    2 -2.288296      5   2   \n",
              "4        4       1       5     3      3  0.911737    2  0.049812      8   2   \n",
              "..     ...     ...     ...   ...    ...       ...  ...       ...    ...  ..   \n",
              "328      3       2       4     3      2  0.382608    2  0.047483      8   2   \n",
              "329      4       1       3     2      2 -0.828817    1  0.059127      7   2   \n",
              "330      1       1       4     4      3  1.218074    2  0.068442      6   3   \n",
              "331      4       3       3     2      2 -0.647800    1  0.040497      3   1   \n",
              "332      2       2       2     2      1 -1.706056    1  0.052141      3   1   \n",
              "\n",
              "         AREA  \n",
              "0   -0.056200  \n",
              "1   -0.062545  \n",
              "2   -0.047741  \n",
              "3   -0.049856  \n",
              "4   -0.039281  \n",
              "..        ...  \n",
              "328 -0.043511  \n",
              "329 -0.054085  \n",
              "330 -0.056200  \n",
              "331 -0.073119  \n",
              "332 -0.068889  \n",
              "\n",
              "[333 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8456a60-ed1f-4342-9052-bf2e993e32bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BUILD</th>\n",
              "      <th>REGION</th>\n",
              "      <th>FAMILY</th>\n",
              "      <th>ROOM</th>\n",
              "      <th>HOUSE</th>\n",
              "      <th>POWER</th>\n",
              "      <th>REF</th>\n",
              "      <th>BYEAR</th>\n",
              "      <th>LIGHT</th>\n",
              "      <th>TV</th>\n",
              "      <th>AREA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1.218074</td>\n",
              "      <td>2</td>\n",
              "      <td>0.068442</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.056200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.647800</td>\n",
              "      <td>1</td>\n",
              "      <td>0.040497</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.062545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.706056</td>\n",
              "      <td>1</td>\n",
              "      <td>0.052141</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.047741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.007276</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.288296</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.049856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.911737</td>\n",
              "      <td>2</td>\n",
              "      <td>0.049812</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.039281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.382608</td>\n",
              "      <td>2</td>\n",
              "      <td>0.047483</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.043511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.828817</td>\n",
              "      <td>1</td>\n",
              "      <td>0.059127</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.054085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>330</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1.218074</td>\n",
              "      <td>2</td>\n",
              "      <td>0.068442</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.056200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.647800</td>\n",
              "      <td>1</td>\n",
              "      <td>0.040497</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.073119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.706056</td>\n",
              "      <td>1</td>\n",
              "      <td>0.052141</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.068889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>333 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8456a60-ed1f-4342-9052-bf2e993e32bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c8456a60-ed1f-4342-9052-bf2e993e32bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c8456a60-ed1f-4342-9052-bf2e993e32bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(2314)\n",
        "\n",
        "hist = autoencoder.fit(\n",
        "    x=x_train,\n",
        "    y=x_train,\n",
        "    epochs=1000,\n",
        "    shuffle=True,\n",
        "    validation_data=(x_test, x_test),\n",
        ")\n",
        "\n",
        "print(hist.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD00CV-Lbso8",
        "outputId": "bc78ea77-194b-4612-96e4-ad03a5193bc7"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 8.9930 - val_loss: 8.1451\n",
            "Epoch 2/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.1498 - val_loss: 6.0714\n",
            "Epoch 3/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.8541 - val_loss: 4.0697\n",
            "Epoch 4/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.5536 - val_loss: 3.6437\n",
            "Epoch 5/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.4086 - val_loss: 3.6262\n",
            "Epoch 6/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.3393 - val_loss: 3.5306\n",
            "Epoch 7/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.2349 - val_loss: 3.4680\n",
            "Epoch 8/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.1727 - val_loss: 3.4284\n",
            "Epoch 9/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.1230 - val_loss: 3.3925\n",
            "Epoch 10/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.0861 - val_loss: 3.3713\n",
            "Epoch 11/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.0501 - val_loss: 3.3518\n",
            "Epoch 12/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0239 - val_loss: 3.3373\n",
            "Epoch 13/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.0025 - val_loss: 3.3263\n",
            "Epoch 14/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.9846 - val_loss: 3.3185\n",
            "Epoch 15/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.9702 - val_loss: 3.3130\n",
            "Epoch 16/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.9599 - val_loss: 3.3103\n",
            "Epoch 17/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.9502 - val_loss: 3.3069\n",
            "Epoch 18/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.9433 - val_loss: 3.3064\n",
            "Epoch 19/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.9361 - val_loss: 3.3052\n",
            "Epoch 20/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.9297 - val_loss: 3.3042\n",
            "Epoch 21/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.9245 - val_loss: 3.3038\n",
            "Epoch 22/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.9200 - val_loss: 3.3027\n",
            "Epoch 23/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.9150 - val_loss: 3.3015\n",
            "Epoch 24/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.9091 - val_loss: 3.3020\n",
            "Epoch 25/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.9057 - val_loss: 3.3014\n",
            "Epoch 26/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.9022 - val_loss: 3.2999\n",
            "Epoch 27/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8996 - val_loss: 3.2985\n",
            "Epoch 28/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8961 - val_loss: 3.2971\n",
            "Epoch 29/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8932 - val_loss: 3.2979\n",
            "Epoch 30/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8907 - val_loss: 3.2975\n",
            "Epoch 31/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8885 - val_loss: 3.2971\n",
            "Epoch 32/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8858 - val_loss: 3.2966\n",
            "Epoch 33/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8838 - val_loss: 3.2957\n",
            "Epoch 34/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8818 - val_loss: 3.2954\n",
            "Epoch 35/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8802 - val_loss: 3.2958\n",
            "Epoch 36/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8781 - val_loss: 3.2952\n",
            "Epoch 37/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8767 - val_loss: 3.2956\n",
            "Epoch 38/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8751 - val_loss: 3.2957\n",
            "Epoch 39/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8736 - val_loss: 3.2953\n",
            "Epoch 40/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8720 - val_loss: 3.2956\n",
            "Epoch 41/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8707 - val_loss: 3.2956\n",
            "Epoch 42/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8695 - val_loss: 3.2953\n",
            "Epoch 43/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8683 - val_loss: 3.2951\n",
            "Epoch 44/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8672 - val_loss: 3.2955\n",
            "Epoch 45/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8663 - val_loss: 3.2946\n",
            "Epoch 46/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8652 - val_loss: 3.2946\n",
            "Epoch 47/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8643 - val_loss: 3.2942\n",
            "Epoch 48/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8634 - val_loss: 3.2945\n",
            "Epoch 49/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8627 - val_loss: 3.2951\n",
            "Epoch 50/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8621 - val_loss: 3.2948\n",
            "Epoch 51/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8612 - val_loss: 3.2949\n",
            "Epoch 52/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8605 - val_loss: 3.2944\n",
            "Epoch 53/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8600 - val_loss: 3.2948\n",
            "Epoch 54/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8583 - val_loss: 3.2946\n",
            "Epoch 55/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8577 - val_loss: 3.2944\n",
            "Epoch 56/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8571 - val_loss: 3.2943\n",
            "Epoch 57/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8567 - val_loss: 3.2948\n",
            "Epoch 58/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8564 - val_loss: 3.2955\n",
            "Epoch 59/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8558 - val_loss: 3.2946\n",
            "Epoch 60/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8552 - val_loss: 3.2944\n",
            "Epoch 61/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8548 - val_loss: 3.2949\n",
            "Epoch 62/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8545 - val_loss: 3.2952\n",
            "Epoch 63/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8540 - val_loss: 3.2954\n",
            "Epoch 64/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8537 - val_loss: 3.2956\n",
            "Epoch 65/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8534 - val_loss: 3.2955\n",
            "Epoch 66/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8531 - val_loss: 3.2954\n",
            "Epoch 67/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8528 - val_loss: 3.2953\n",
            "Epoch 68/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8525 - val_loss: 3.2958\n",
            "Epoch 69/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8522 - val_loss: 3.2960\n",
            "Epoch 70/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8519 - val_loss: 3.2962\n",
            "Epoch 71/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8518 - val_loss: 3.2950\n",
            "Epoch 72/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8514 - val_loss: 3.2944\n",
            "Epoch 73/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8512 - val_loss: 3.2947\n",
            "Epoch 74/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8510 - val_loss: 3.2945\n",
            "Epoch 75/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8508 - val_loss: 3.2945\n",
            "Epoch 76/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8506 - val_loss: 3.2945\n",
            "Epoch 77/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8505 - val_loss: 3.2949\n",
            "Epoch 78/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8503 - val_loss: 3.2947\n",
            "Epoch 79/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8501 - val_loss: 3.2947\n",
            "Epoch 80/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8500 - val_loss: 3.2950\n",
            "Epoch 81/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8497 - val_loss: 3.2947\n",
            "Epoch 82/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8496 - val_loss: 3.2947\n",
            "Epoch 83/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8494 - val_loss: 3.2942\n",
            "Epoch 84/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8493 - val_loss: 3.2930\n",
            "Epoch 85/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8492 - val_loss: 3.2925\n",
            "Epoch 86/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8491 - val_loss: 3.2921\n",
            "Epoch 87/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8490 - val_loss: 3.2920\n",
            "Epoch 88/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8488 - val_loss: 3.2908\n",
            "Epoch 89/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8487 - val_loss: 3.2901\n",
            "Epoch 90/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8485 - val_loss: 3.2895\n",
            "Epoch 91/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8484 - val_loss: 3.2891\n",
            "Epoch 92/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8483 - val_loss: 3.2887\n",
            "Epoch 93/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8482 - val_loss: 3.2882\n",
            "Epoch 94/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8480 - val_loss: 3.2875\n",
            "Epoch 95/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8480 - val_loss: 3.2866\n",
            "Epoch 96/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8479 - val_loss: 3.2857\n",
            "Epoch 97/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8477 - val_loss: 3.2847\n",
            "Epoch 98/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8477 - val_loss: 3.2839\n",
            "Epoch 99/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8476 - val_loss: 3.2833\n",
            "Epoch 100/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8475 - val_loss: 3.2826\n",
            "Epoch 101/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8474 - val_loss: 3.2817\n",
            "Epoch 102/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8473 - val_loss: 3.2810\n",
            "Epoch 103/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8472 - val_loss: 3.2800\n",
            "Epoch 104/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8472 - val_loss: 3.2794\n",
            "Epoch 105/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8470 - val_loss: 3.2783\n",
            "Epoch 106/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8470 - val_loss: 3.2778\n",
            "Epoch 107/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8469 - val_loss: 3.2766\n",
            "Epoch 108/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8468 - val_loss: 3.2759\n",
            "Epoch 109/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8468 - val_loss: 3.2751\n",
            "Epoch 110/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8467 - val_loss: 3.2740\n",
            "Epoch 111/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8466 - val_loss: 3.2725\n",
            "Epoch 112/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8465 - val_loss: 3.2717\n",
            "Epoch 113/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8464 - val_loss: 3.2706\n",
            "Epoch 114/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8464 - val_loss: 3.2698\n",
            "Epoch 115/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8463 - val_loss: 3.2685\n",
            "Epoch 116/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8463 - val_loss: 3.2669\n",
            "Epoch 117/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8462 - val_loss: 3.2659\n",
            "Epoch 118/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8461 - val_loss: 3.2648\n",
            "Epoch 119/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8461 - val_loss: 3.2634\n",
            "Epoch 120/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8460 - val_loss: 3.2622\n",
            "Epoch 121/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8459 - val_loss: 3.2609\n",
            "Epoch 122/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8459 - val_loss: 3.2595\n",
            "Epoch 123/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8458 - val_loss: 3.2584\n",
            "Epoch 124/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8458 - val_loss: 3.2571\n",
            "Epoch 125/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8457 - val_loss: 3.2559\n",
            "Epoch 126/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8457 - val_loss: 3.2545\n",
            "Epoch 127/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8456 - val_loss: 3.2530\n",
            "Epoch 128/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8456 - val_loss: 3.2516\n",
            "Epoch 129/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8455 - val_loss: 3.2504\n",
            "Epoch 130/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8455 - val_loss: 3.2490\n",
            "Epoch 131/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8455 - val_loss: 3.2477\n",
            "Epoch 132/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8454 - val_loss: 3.2464\n",
            "Epoch 133/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8453 - val_loss: 3.2451\n",
            "Epoch 134/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8453 - val_loss: 3.2433\n",
            "Epoch 135/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8453 - val_loss: 3.2419\n",
            "Epoch 136/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8453 - val_loss: 3.2405\n",
            "Epoch 137/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8452 - val_loss: 3.2389\n",
            "Epoch 138/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8452 - val_loss: 3.2376\n",
            "Epoch 139/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8451 - val_loss: 3.2363\n",
            "Epoch 140/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8451 - val_loss: 3.2348\n",
            "Epoch 141/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.2334\n",
            "Epoch 142/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.2318\n",
            "Epoch 143/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.2304\n",
            "Epoch 144/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.2292\n",
            "Epoch 145/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.2276\n",
            "Epoch 146/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.2260\n",
            "Epoch 147/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.2247\n",
            "Epoch 148/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8448 - val_loss: 3.2232\n",
            "Epoch 149/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8448 - val_loss: 3.2216\n",
            "Epoch 150/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8448 - val_loss: 3.2201\n",
            "Epoch 151/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8448 - val_loss: 3.2185\n",
            "Epoch 152/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8447 - val_loss: 3.2171\n",
            "Epoch 153/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8447 - val_loss: 3.2154\n",
            "Epoch 154/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8447 - val_loss: 3.2141\n",
            "Epoch 155/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8447 - val_loss: 3.2125\n",
            "Epoch 156/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8446 - val_loss: 3.2110\n",
            "Epoch 157/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8446 - val_loss: 3.2094\n",
            "Epoch 158/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8446 - val_loss: 3.2078\n",
            "Epoch 159/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8446 - val_loss: 3.2064\n",
            "Epoch 160/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8445 - val_loss: 3.2051\n",
            "Epoch 161/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8445 - val_loss: 3.2035\n",
            "Epoch 162/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8445 - val_loss: 3.2019\n",
            "Epoch 163/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8445 - val_loss: 3.2005\n",
            "Epoch 164/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8445 - val_loss: 3.1989\n",
            "Epoch 165/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8445 - val_loss: 3.1974\n",
            "Epoch 166/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8445 - val_loss: 3.1961\n",
            "Epoch 167/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8444 - val_loss: 3.1946\n",
            "Epoch 168/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8444 - val_loss: 3.1931\n",
            "Epoch 169/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8444 - val_loss: 3.1917\n",
            "Epoch 170/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8444 - val_loss: 3.1903\n",
            "Epoch 171/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8443 - val_loss: 3.1889\n",
            "Epoch 172/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8443 - val_loss: 3.1876\n",
            "Epoch 173/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8443 - val_loss: 3.1861\n",
            "Epoch 174/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8443 - val_loss: 3.1847\n",
            "Epoch 175/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8443 - val_loss: 3.1833\n",
            "Epoch 176/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8443 - val_loss: 3.1818\n",
            "Epoch 177/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8443 - val_loss: 3.1804\n",
            "Epoch 178/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8443 - val_loss: 3.1790\n",
            "Epoch 179/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8442 - val_loss: 3.1776\n",
            "Epoch 180/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8442 - val_loss: 3.1763\n",
            "Epoch 181/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8442 - val_loss: 3.1750\n",
            "Epoch 182/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8442 - val_loss: 3.1737\n",
            "Epoch 183/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8442 - val_loss: 3.1722\n",
            "Epoch 184/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8442 - val_loss: 3.1710\n",
            "Epoch 185/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8442 - val_loss: 3.1696\n",
            "Epoch 186/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8442 - val_loss: 3.1684\n",
            "Epoch 187/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8442 - val_loss: 3.1670\n",
            "Epoch 188/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8442 - val_loss: 3.1658\n",
            "Epoch 189/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8441 - val_loss: 3.1646\n",
            "Epoch 190/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8441 - val_loss: 3.1630\n",
            "Epoch 191/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8441 - val_loss: 3.1618\n",
            "Epoch 192/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8441 - val_loss: 3.1603\n",
            "Epoch 193/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8441 - val_loss: 3.1594\n",
            "Epoch 194/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8442 - val_loss: 3.1579\n",
            "Epoch 195/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8442 - val_loss: 3.1567\n",
            "Epoch 196/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8443 - val_loss: 3.1558\n",
            "Epoch 197/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8441 - val_loss: 3.1539\n",
            "Epoch 198/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8443 - val_loss: 3.1537\n",
            "Epoch 199/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8443 - val_loss: 3.1518\n",
            "Epoch 200/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8442 - val_loss: 3.1504\n",
            "Epoch 201/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8441 - val_loss: 3.1496\n",
            "Epoch 202/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8441 - val_loss: 3.1483\n",
            "Epoch 203/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8441 - val_loss: 3.1472\n",
            "Epoch 204/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8440 - val_loss: 3.1460\n",
            "Epoch 205/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8441 - val_loss: 3.1449\n",
            "Epoch 206/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8440 - val_loss: 3.1436\n",
            "Epoch 207/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8440 - val_loss: 3.1427\n",
            "Epoch 208/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8440 - val_loss: 3.1416\n",
            "Epoch 209/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8440 - val_loss: 3.1405\n",
            "Epoch 210/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8441 - val_loss: 3.1395\n",
            "Epoch 211/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8441 - val_loss: 3.1385\n",
            "Epoch 212/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8440 - val_loss: 3.1374\n",
            "Epoch 213/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8441 - val_loss: 3.1364\n",
            "Epoch 214/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8441 - val_loss: 3.1357\n",
            "Epoch 215/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.1347\n",
            "Epoch 216/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8445 - val_loss: 3.1337\n",
            "Epoch 217/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8455 - val_loss: 3.1325\n",
            "Epoch 218/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8441 - val_loss: 3.1314\n",
            "Epoch 219/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8441 - val_loss: 3.1304\n",
            "Epoch 220/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8440 - val_loss: 3.1295\n",
            "Epoch 221/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8440 - val_loss: 3.1286\n",
            "Epoch 222/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8440 - val_loss: 3.1278\n",
            "Epoch 223/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8444 - val_loss: 3.1269\n",
            "Epoch 224/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8440 - val_loss: 3.1260\n",
            "Epoch 225/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8440 - val_loss: 3.1254\n",
            "Epoch 226/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8446 - val_loss: 3.1241\n",
            "Epoch 227/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8440 - val_loss: 3.1234\n",
            "Epoch 228/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8440 - val_loss: 3.1225\n",
            "Epoch 229/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8440 - val_loss: 3.1217\n",
            "Epoch 230/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8440 - val_loss: 3.1208\n",
            "Epoch 231/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.1200\n",
            "Epoch 232/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8440 - val_loss: 3.1192\n",
            "Epoch 233/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.1185\n",
            "Epoch 234/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.1178\n",
            "Epoch 235/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8439 - val_loss: 3.1170\n",
            "Epoch 236/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.1163\n",
            "Epoch 237/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.1156\n",
            "Epoch 238/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.1148\n",
            "Epoch 239/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.1140\n",
            "Epoch 240/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.1132\n",
            "Epoch 241/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8439 - val_loss: 3.1123\n",
            "Epoch 242/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8439 - val_loss: 3.1114\n",
            "Epoch 243/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.1105\n",
            "Epoch 244/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.1095\n",
            "Epoch 245/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.1086\n",
            "Epoch 246/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.1077\n",
            "Epoch 247/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.1068\n",
            "Epoch 248/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.1059\n",
            "Epoch 249/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.1050\n",
            "Epoch 250/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.1040\n",
            "Epoch 251/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.1031\n",
            "Epoch 252/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.1022\n",
            "Epoch 253/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.1014\n",
            "Epoch 254/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.1005\n",
            "Epoch 255/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0997\n",
            "Epoch 256/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0988\n",
            "Epoch 257/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0980\n",
            "Epoch 258/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0970\n",
            "Epoch 259/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0963\n",
            "Epoch 260/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0954\n",
            "Epoch 261/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0947\n",
            "Epoch 262/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0938\n",
            "Epoch 263/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8439 - val_loss: 3.0930\n",
            "Epoch 264/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0923\n",
            "Epoch 265/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0915\n",
            "Epoch 266/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0907\n",
            "Epoch 267/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8439 - val_loss: 3.0899\n",
            "Epoch 268/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0891\n",
            "Epoch 269/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0883\n",
            "Epoch 270/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0875\n",
            "Epoch 271/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0868\n",
            "Epoch 272/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0860\n",
            "Epoch 273/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0853\n",
            "Epoch 274/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0846\n",
            "Epoch 275/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0839\n",
            "Epoch 276/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8439 - val_loss: 3.0831\n",
            "Epoch 277/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0824\n",
            "Epoch 278/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0817\n",
            "Epoch 279/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0810\n",
            "Epoch 280/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0802\n",
            "Epoch 281/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0796\n",
            "Epoch 282/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0789\n",
            "Epoch 283/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0782\n",
            "Epoch 284/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0775\n",
            "Epoch 285/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0769\n",
            "Epoch 286/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0762\n",
            "Epoch 287/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0755\n",
            "Epoch 288/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0749\n",
            "Epoch 289/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8439 - val_loss: 3.0743\n",
            "Epoch 290/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0737\n",
            "Epoch 291/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0731\n",
            "Epoch 292/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0725\n",
            "Epoch 293/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0718\n",
            "Epoch 294/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0712\n",
            "Epoch 295/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0705\n",
            "Epoch 296/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0700\n",
            "Epoch 297/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0692\n",
            "Epoch 298/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0687\n",
            "Epoch 299/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0682\n",
            "Epoch 300/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0677\n",
            "Epoch 301/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0672\n",
            "Epoch 302/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0666\n",
            "Epoch 303/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0660\n",
            "Epoch 304/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0655\n",
            "Epoch 305/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0648\n",
            "Epoch 306/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8439 - val_loss: 3.0643\n",
            "Epoch 307/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0638\n",
            "Epoch 308/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0632\n",
            "Epoch 309/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0627\n",
            "Epoch 310/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0621\n",
            "Epoch 311/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0619\n",
            "Epoch 312/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0614\n",
            "Epoch 313/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0608\n",
            "Epoch 314/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0603\n",
            "Epoch 315/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0598\n",
            "Epoch 316/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8439 - val_loss: 3.0593\n",
            "Epoch 317/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8439 - val_loss: 3.0588\n",
            "Epoch 318/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0583\n",
            "Epoch 319/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0579\n",
            "Epoch 320/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0573\n",
            "Epoch 321/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0569\n",
            "Epoch 322/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8439 - val_loss: 3.0565\n",
            "Epoch 323/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0560\n",
            "Epoch 324/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0557\n",
            "Epoch 325/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0550\n",
            "Epoch 326/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0548\n",
            "Epoch 327/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0543\n",
            "Epoch 328/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8439 - val_loss: 3.0542\n",
            "Epoch 329/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8439 - val_loss: 3.0533\n",
            "Epoch 330/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8440 - val_loss: 3.0540\n",
            "Epoch 331/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8442 - val_loss: 3.0537\n",
            "Epoch 332/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8441 - val_loss: 3.0519\n",
            "Epoch 333/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8445 - val_loss: 3.0524\n",
            "Epoch 334/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8447 - val_loss: 3.0561\n",
            "Epoch 335/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0556\n",
            "Epoch 336/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8447 - val_loss: 3.0556\n",
            "Epoch 337/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8444 - val_loss: 3.0556\n",
            "Epoch 338/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8443 - val_loss: 3.0550\n",
            "Epoch 339/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8442 - val_loss: 3.0541\n",
            "Epoch 340/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8441 - val_loss: 3.0526\n",
            "Epoch 341/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8439 - val_loss: 3.0533\n",
            "Epoch 342/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8440 - val_loss: 3.0537\n",
            "Epoch 343/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0536\n",
            "Epoch 344/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0532\n",
            "Epoch 345/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0529\n",
            "Epoch 346/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0524\n",
            "Epoch 347/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0521\n",
            "Epoch 348/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0517\n",
            "Epoch 349/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0514\n",
            "Epoch 350/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0510\n",
            "Epoch 351/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0506\n",
            "Epoch 352/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0503\n",
            "Epoch 353/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0499\n",
            "Epoch 354/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0496\n",
            "Epoch 355/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0493\n",
            "Epoch 356/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0490\n",
            "Epoch 357/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0486\n",
            "Epoch 358/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0483\n",
            "Epoch 359/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0481\n",
            "Epoch 360/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0478\n",
            "Epoch 361/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0475\n",
            "Epoch 362/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0472\n",
            "Epoch 363/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0468\n",
            "Epoch 364/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0466\n",
            "Epoch 365/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0463\n",
            "Epoch 366/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0459\n",
            "Epoch 367/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0457\n",
            "Epoch 368/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0454\n",
            "Epoch 369/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0452\n",
            "Epoch 370/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0449\n",
            "Epoch 371/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0447\n",
            "Epoch 372/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0445\n",
            "Epoch 373/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0442\n",
            "Epoch 374/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0440\n",
            "Epoch 375/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0437\n",
            "Epoch 376/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0435\n",
            "Epoch 377/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0433\n",
            "Epoch 378/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0430\n",
            "Epoch 379/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0428\n",
            "Epoch 380/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0426\n",
            "Epoch 381/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0423\n",
            "Epoch 382/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0421\n",
            "Epoch 383/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0420\n",
            "Epoch 384/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0418\n",
            "Epoch 385/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0415\n",
            "Epoch 386/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0413\n",
            "Epoch 387/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0412\n",
            "Epoch 388/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0409\n",
            "Epoch 389/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0407\n",
            "Epoch 390/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0405\n",
            "Epoch 391/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0404\n",
            "Epoch 392/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0402\n",
            "Epoch 393/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0400\n",
            "Epoch 394/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0399\n",
            "Epoch 395/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0397\n",
            "Epoch 396/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0395\n",
            "Epoch 397/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0393\n",
            "Epoch 398/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0391\n",
            "Epoch 399/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0389\n",
            "Epoch 400/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0387\n",
            "Epoch 401/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0386\n",
            "Epoch 402/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0384\n",
            "Epoch 403/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0382\n",
            "Epoch 404/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0380\n",
            "Epoch 405/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0379\n",
            "Epoch 406/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0377\n",
            "Epoch 407/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0375\n",
            "Epoch 408/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0374\n",
            "Epoch 409/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0373\n",
            "Epoch 410/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0371\n",
            "Epoch 411/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0369\n",
            "Epoch 412/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0367\n",
            "Epoch 413/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0366\n",
            "Epoch 414/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0364\n",
            "Epoch 415/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0363\n",
            "Epoch 416/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0361\n",
            "Epoch 417/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0360\n",
            "Epoch 418/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0358\n",
            "Epoch 419/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0357\n",
            "Epoch 420/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0355\n",
            "Epoch 421/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0354\n",
            "Epoch 422/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0353\n",
            "Epoch 423/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0351\n",
            "Epoch 424/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0349\n",
            "Epoch 425/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0348\n",
            "Epoch 426/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0346\n",
            "Epoch 427/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0345\n",
            "Epoch 428/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0343\n",
            "Epoch 429/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0342\n",
            "Epoch 430/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0341\n",
            "Epoch 431/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0339\n",
            "Epoch 432/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0338\n",
            "Epoch 433/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0337\n",
            "Epoch 434/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0336\n",
            "Epoch 435/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0334\n",
            "Epoch 436/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0334\n",
            "Epoch 437/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0333\n",
            "Epoch 438/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0331\n",
            "Epoch 439/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0329\n",
            "Epoch 440/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0328\n",
            "Epoch 441/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0327\n",
            "Epoch 442/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8452 - val_loss: 3.0326\n",
            "Epoch 443/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8453 - val_loss: 3.0325\n",
            "Epoch 444/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0323\n",
            "Epoch 445/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0321\n",
            "Epoch 446/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0320\n",
            "Epoch 447/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0319\n",
            "Epoch 448/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0318\n",
            "Epoch 449/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0316\n",
            "Epoch 450/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0315\n",
            "Epoch 451/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0314\n",
            "Epoch 452/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0313\n",
            "Epoch 453/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8452 - val_loss: 3.0315\n",
            "Epoch 454/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0314\n",
            "Epoch 455/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8451 - val_loss: 3.0311\n",
            "Epoch 456/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0309\n",
            "Epoch 457/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0308\n",
            "Epoch 458/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0307\n",
            "Epoch 459/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0305\n",
            "Epoch 460/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0304\n",
            "Epoch 461/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0303\n",
            "Epoch 462/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0302\n",
            "Epoch 463/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0301\n",
            "Epoch 464/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0300\n",
            "Epoch 465/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0298\n",
            "Epoch 466/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8452 - val_loss: 3.0298\n",
            "Epoch 467/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0297\n",
            "Epoch 468/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8452 - val_loss: 3.0296\n",
            "Epoch 469/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8451 - val_loss: 3.0295\n",
            "Epoch 470/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0293\n",
            "Epoch 471/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0292\n",
            "Epoch 472/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0291\n",
            "Epoch 473/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0290\n",
            "Epoch 474/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0289\n",
            "Epoch 475/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0288\n",
            "Epoch 476/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0287\n",
            "Epoch 477/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0286\n",
            "Epoch 478/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0285\n",
            "Epoch 479/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0285\n",
            "Epoch 480/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0283\n",
            "Epoch 481/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0284\n",
            "Epoch 482/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0281\n",
            "Epoch 483/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0282\n",
            "Epoch 484/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8451 - val_loss: 3.0279\n",
            "Epoch 485/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0280\n",
            "Epoch 486/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0278\n",
            "Epoch 487/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8451 - val_loss: 3.0277\n",
            "Epoch 488/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0276\n",
            "Epoch 489/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0275\n",
            "Epoch 490/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0274\n",
            "Epoch 491/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0273\n",
            "Epoch 492/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0274\n",
            "Epoch 493/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0273\n",
            "Epoch 494/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8455 - val_loss: 3.0276\n",
            "Epoch 495/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8455 - val_loss: 3.0273\n",
            "Epoch 496/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0270\n",
            "Epoch 497/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0268\n",
            "Epoch 498/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0267\n",
            "Epoch 499/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0267\n",
            "Epoch 500/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0266\n",
            "Epoch 501/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0266\n",
            "Epoch 502/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0265\n",
            "Epoch 503/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0264\n",
            "Epoch 504/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0264\n",
            "Epoch 505/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0263\n",
            "Epoch 506/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0262\n",
            "Epoch 507/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0261\n",
            "Epoch 508/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0261\n",
            "Epoch 509/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0260\n",
            "Epoch 510/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0259\n",
            "Epoch 511/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0258\n",
            "Epoch 512/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0258\n",
            "Epoch 513/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0257\n",
            "Epoch 514/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0256\n",
            "Epoch 515/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0256\n",
            "Epoch 516/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0256\n",
            "Epoch 517/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0255\n",
            "Epoch 518/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.8449 - val_loss: 3.0254\n",
            "Epoch 519/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0253\n",
            "Epoch 520/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0253\n",
            "Epoch 521/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0253\n",
            "Epoch 522/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0252\n",
            "Epoch 523/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0251\n",
            "Epoch 524/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8451 - val_loss: 3.0251\n",
            "Epoch 525/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0249\n",
            "Epoch 526/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8451 - val_loss: 3.0252\n",
            "Epoch 527/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8452 - val_loss: 3.0249\n",
            "Epoch 528/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0248\n",
            "Epoch 529/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0249\n",
            "Epoch 530/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0248\n",
            "Epoch 531/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0247\n",
            "Epoch 532/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0249\n",
            "Epoch 533/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0246\n",
            "Epoch 534/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0245\n",
            "Epoch 535/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0247\n",
            "Epoch 536/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0247\n",
            "Epoch 537/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0248\n",
            "Epoch 538/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0245\n",
            "Epoch 539/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0244\n",
            "Epoch 540/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0245\n",
            "Epoch 541/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0241\n",
            "Epoch 542/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0243\n",
            "Epoch 543/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8452 - val_loss: 3.0242\n",
            "Epoch 544/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0240\n",
            "Epoch 545/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0238\n",
            "Epoch 546/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0237\n",
            "Epoch 547/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0237\n",
            "Epoch 548/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0235\n",
            "Epoch 549/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8453 - val_loss: 3.0237\n",
            "Epoch 550/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8453 - val_loss: 3.0234\n",
            "Epoch 551/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8453 - val_loss: 3.0233\n",
            "Epoch 552/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0234\n",
            "Epoch 553/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0231\n",
            "Epoch 554/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0230\n",
            "Epoch 555/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0231\n",
            "Epoch 556/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8451 - val_loss: 3.0229\n",
            "Epoch 557/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0229\n",
            "Epoch 558/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0227\n",
            "Epoch 559/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0227\n",
            "Epoch 560/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0225\n",
            "Epoch 561/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0224\n",
            "Epoch 562/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0224\n",
            "Epoch 563/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0222\n",
            "Epoch 564/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0224\n",
            "Epoch 565/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0226\n",
            "Epoch 566/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8452 - val_loss: 3.0220\n",
            "Epoch 567/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8458 - val_loss: 3.0224\n",
            "Epoch 568/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8454 - val_loss: 3.0219\n",
            "Epoch 569/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0217\n",
            "Epoch 570/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0219\n",
            "Epoch 571/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0218\n",
            "Epoch 572/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0215\n",
            "Epoch 573/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0215\n",
            "Epoch 574/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0216\n",
            "Epoch 575/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0214\n",
            "Epoch 576/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0213\n",
            "Epoch 577/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0213\n",
            "Epoch 578/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0212\n",
            "Epoch 579/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0212\n",
            "Epoch 580/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8452 - val_loss: 3.0211\n",
            "Epoch 581/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0210\n",
            "Epoch 582/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0210\n",
            "Epoch 583/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0209\n",
            "Epoch 584/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0209\n",
            "Epoch 585/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0208\n",
            "Epoch 586/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0207\n",
            "Epoch 587/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0207\n",
            "Epoch 588/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0206\n",
            "Epoch 589/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8458 - val_loss: 3.0206\n",
            "Epoch 590/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8457 - val_loss: 3.0207\n",
            "Epoch 591/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8454 - val_loss: 3.0205\n",
            "Epoch 592/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0204\n",
            "Epoch 593/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8452 - val_loss: 3.0205\n",
            "Epoch 594/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8453 - val_loss: 3.0210\n",
            "Epoch 595/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8453 - val_loss: 3.0207\n",
            "Epoch 596/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8452 - val_loss: 3.0205\n",
            "Epoch 597/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0204\n",
            "Epoch 598/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0203\n",
            "Epoch 599/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0202\n",
            "Epoch 600/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0201\n",
            "Epoch 601/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0200\n",
            "Epoch 602/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0199\n",
            "Epoch 603/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0199\n",
            "Epoch 604/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0198\n",
            "Epoch 605/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0198\n",
            "Epoch 606/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0197\n",
            "Epoch 607/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0197\n",
            "Epoch 608/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0196\n",
            "Epoch 609/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0195\n",
            "Epoch 610/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0195\n",
            "Epoch 611/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0195\n",
            "Epoch 612/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0194\n",
            "Epoch 613/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0194\n",
            "Epoch 614/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0193\n",
            "Epoch 615/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0193\n",
            "Epoch 616/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.8449 - val_loss: 3.0192\n",
            "Epoch 617/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0192\n",
            "Epoch 618/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0191\n",
            "Epoch 619/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0191\n",
            "Epoch 620/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0190\n",
            "Epoch 621/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0190\n",
            "Epoch 622/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0190\n",
            "Epoch 623/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0189\n",
            "Epoch 624/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0189\n",
            "Epoch 625/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0189\n",
            "Epoch 626/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0188\n",
            "Epoch 627/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0188\n",
            "Epoch 628/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0188\n",
            "Epoch 629/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8451 - val_loss: 3.0188\n",
            "Epoch 630/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0187\n",
            "Epoch 631/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0186\n",
            "Epoch 632/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0187\n",
            "Epoch 633/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0187\n",
            "Epoch 634/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8454 - val_loss: 3.0188\n",
            "Epoch 635/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8453 - val_loss: 3.0185\n",
            "Epoch 636/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0186\n",
            "Epoch 637/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0185\n",
            "Epoch 638/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0185\n",
            "Epoch 639/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0185\n",
            "Epoch 640/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0184\n",
            "Epoch 641/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0184\n",
            "Epoch 642/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0183\n",
            "Epoch 643/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8452 - val_loss: 3.0187\n",
            "Epoch 644/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8455 - val_loss: 3.0190\n",
            "Epoch 645/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8458 - val_loss: 3.0184\n",
            "Epoch 646/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8460 - val_loss: 3.0203\n",
            "Epoch 647/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8471 - val_loss: 3.0194\n",
            "Epoch 648/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8469 - val_loss: 3.0188\n",
            "Epoch 649/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8454 - val_loss: 3.0184\n",
            "Epoch 650/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8457 - val_loss: 3.0184\n",
            "Epoch 651/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0186\n",
            "Epoch 652/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0183\n",
            "Epoch 653/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0181\n",
            "Epoch 654/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0181\n",
            "Epoch 655/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0181\n",
            "Epoch 656/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0181\n",
            "Epoch 657/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0180\n",
            "Epoch 658/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0180\n",
            "Epoch 659/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0180\n",
            "Epoch 660/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0180\n",
            "Epoch 661/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0179\n",
            "Epoch 662/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0179\n",
            "Epoch 663/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0179\n",
            "Epoch 664/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0178\n",
            "Epoch 665/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0178\n",
            "Epoch 666/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0178\n",
            "Epoch 667/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0178\n",
            "Epoch 668/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0177\n",
            "Epoch 669/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0177\n",
            "Epoch 670/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0177\n",
            "Epoch 671/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0177\n",
            "Epoch 672/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0176\n",
            "Epoch 673/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0176\n",
            "Epoch 674/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0176\n",
            "Epoch 675/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0176\n",
            "Epoch 676/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0176\n",
            "Epoch 677/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0176\n",
            "Epoch 678/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0175\n",
            "Epoch 679/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0176\n",
            "Epoch 680/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0176\n",
            "Epoch 681/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8453 - val_loss: 3.0175\n",
            "Epoch 682/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0175\n",
            "Epoch 683/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8454 - val_loss: 3.0175\n",
            "Epoch 684/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8453 - val_loss: 3.0175\n",
            "Epoch 685/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0175\n",
            "Epoch 686/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8452 - val_loss: 3.0174\n",
            "Epoch 687/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0174\n",
            "Epoch 688/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0173\n",
            "Epoch 689/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0173\n",
            "Epoch 690/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0173\n",
            "Epoch 691/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0173\n",
            "Epoch 692/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0172\n",
            "Epoch 693/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0172\n",
            "Epoch 694/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0172\n",
            "Epoch 695/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0172\n",
            "Epoch 696/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0172\n",
            "Epoch 697/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0172\n",
            "Epoch 698/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0172\n",
            "Epoch 699/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0171\n",
            "Epoch 700/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0171\n",
            "Epoch 701/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0171\n",
            "Epoch 702/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0171\n",
            "Epoch 703/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0171\n",
            "Epoch 704/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0171\n",
            "Epoch 705/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0171\n",
            "Epoch 706/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0175\n",
            "Epoch 707/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8457 - val_loss: 3.0171\n",
            "Epoch 708/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8452 - val_loss: 3.0171\n",
            "Epoch 709/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0170\n",
            "Epoch 710/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0170\n",
            "Epoch 711/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0170\n",
            "Epoch 712/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0170\n",
            "Epoch 713/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0170\n",
            "Epoch 714/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0170\n",
            "Epoch 715/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0169\n",
            "Epoch 716/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0169\n",
            "Epoch 717/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0169\n",
            "Epoch 718/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0169\n",
            "Epoch 719/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0169\n",
            "Epoch 720/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0169\n",
            "Epoch 721/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0169\n",
            "Epoch 722/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0169\n",
            "Epoch 723/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0169\n",
            "Epoch 724/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0174\n",
            "Epoch 725/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8453 - val_loss: 3.0169\n",
            "Epoch 726/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8453 - val_loss: 3.0170\n",
            "Epoch 727/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8452 - val_loss: 3.0169\n",
            "Epoch 728/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0169\n",
            "Epoch 729/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0169\n",
            "Epoch 730/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0168\n",
            "Epoch 731/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0168\n",
            "Epoch 732/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0168\n",
            "Epoch 733/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0168\n",
            "Epoch 734/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0168\n",
            "Epoch 735/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0168\n",
            "Epoch 736/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0168\n",
            "Epoch 737/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0168\n",
            "Epoch 738/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0168\n",
            "Epoch 739/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0167\n",
            "Epoch 740/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0167\n",
            "Epoch 741/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0167\n",
            "Epoch 742/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0167\n",
            "Epoch 743/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0167\n",
            "Epoch 744/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0167\n",
            "Epoch 745/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0167\n",
            "Epoch 746/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0167\n",
            "Epoch 747/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0167\n",
            "Epoch 748/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0167\n",
            "Epoch 749/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0167\n",
            "Epoch 750/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.8449 - val_loss: 3.0167\n",
            "Epoch 751/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0167\n",
            "Epoch 752/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0167\n",
            "Epoch 753/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0167\n",
            "Epoch 754/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 755/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 756/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 757/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 758/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 759/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 760/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 761/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 762/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 763/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 764/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 765/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 766/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 767/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 768/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 769/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 770/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 771/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 772/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 773/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 774/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 775/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 776/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0166\n",
            "Epoch 777/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 778/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 779/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 780/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 781/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 782/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 783/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 784/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 785/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 786/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 787/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 788/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 789/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 790/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 791/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0169\n",
            "Epoch 792/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8456 - val_loss: 3.0180\n",
            "Epoch 793/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8461 - val_loss: 3.0177\n",
            "Epoch 794/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8458 - val_loss: 3.0170\n",
            "Epoch 795/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8453 - val_loss: 3.0169\n",
            "Epoch 796/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8452 - val_loss: 3.0166\n",
            "Epoch 797/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0167\n",
            "Epoch 798/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0166\n",
            "Epoch 799/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0167\n",
            "Epoch 800/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0167\n",
            "Epoch 801/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0167\n",
            "Epoch 802/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0166\n",
            "Epoch 803/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0167\n",
            "Epoch 804/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0167\n",
            "Epoch 805/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0166\n",
            "Epoch 806/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0167\n",
            "Epoch 807/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0167\n",
            "Epoch 808/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8452 - val_loss: 3.0170\n",
            "Epoch 809/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8456 - val_loss: 3.0170\n",
            "Epoch 810/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8456 - val_loss: 3.0167\n",
            "Epoch 811/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8458 - val_loss: 3.0169\n",
            "Epoch 812/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8456 - val_loss: 3.0167\n",
            "Epoch 813/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8453 - val_loss: 3.0166\n",
            "Epoch 814/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0167\n",
            "Epoch 815/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0166\n",
            "Epoch 816/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0166\n",
            "Epoch 817/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0166\n",
            "Epoch 818/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0166\n",
            "Epoch 819/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0166\n",
            "Epoch 820/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0166\n",
            "Epoch 821/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8453 - val_loss: 3.0172\n",
            "Epoch 822/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8468 - val_loss: 3.0167\n",
            "Epoch 823/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8452 - val_loss: 3.0169\n",
            "Epoch 824/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8454 - val_loss: 3.0165\n",
            "Epoch 825/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 826/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0166\n",
            "Epoch 827/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 828/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 829/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 830/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 831/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 832/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 833/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 834/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 835/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 836/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 837/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 838/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 839/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0166\n",
            "Epoch 840/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 841/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 842/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 843/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 844/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8452 - val_loss: 3.0168\n",
            "Epoch 845/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8453 - val_loss: 3.0166\n",
            "Epoch 846/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0165\n",
            "Epoch 847/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 848/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 849/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 850/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 851/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 852/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 853/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 854/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 855/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 856/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 857/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 858/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 859/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 860/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 861/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0165\n",
            "Epoch 862/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 863/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 864/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 865/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 866/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 867/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 868/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 869/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 870/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 871/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 872/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 873/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 874/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 875/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 876/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 877/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 878/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 879/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 880/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 881/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 882/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 883/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 884/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 885/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 886/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0166\n",
            "Epoch 887/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0166\n",
            "Epoch 888/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 889/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 890/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 891/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 892/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 893/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 894/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 895/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 896/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 897/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 898/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 899/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8452 - val_loss: 3.0176\n",
            "Epoch 900/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8462 - val_loss: 3.0182\n",
            "Epoch 901/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8461 - val_loss: 3.0183\n",
            "Epoch 902/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8463 - val_loss: 3.0166\n",
            "Epoch 903/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8457 - val_loss: 3.0172\n",
            "Epoch 904/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8453 - val_loss: 3.0165\n",
            "Epoch 905/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8457 - val_loss: 3.0169\n",
            "Epoch 906/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8453 - val_loss: 3.0169\n",
            "Epoch 907/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8452 - val_loss: 3.0167\n",
            "Epoch 908/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 909/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 910/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 911/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 912/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 913/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 914/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 915/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 916/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 917/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 918/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 919/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 920/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 921/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 922/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 923/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 924/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 925/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 926/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 927/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 928/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 929/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 930/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 931/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 932/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 933/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 934/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0166\n",
            "Epoch 935/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8452 - val_loss: 3.0167\n",
            "Epoch 936/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8454 - val_loss: 3.0167\n",
            "Epoch 937/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8453 - val_loss: 3.0166\n",
            "Epoch 938/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8453 - val_loss: 3.0165\n",
            "Epoch 939/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8452 - val_loss: 3.0168\n",
            "Epoch 940/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0167\n",
            "Epoch 941/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0166\n",
            "Epoch 942/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0166\n",
            "Epoch 943/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0166\n",
            "Epoch 944/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0166\n",
            "Epoch 945/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0166\n",
            "Epoch 946/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 947/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 948/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0166\n",
            "Epoch 949/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 950/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 951/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 952/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 953/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 954/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 955/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 956/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 957/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 958/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 959/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8451 - val_loss: 3.0166\n",
            "Epoch 960/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8454 - val_loss: 3.0166\n",
            "Epoch 961/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8457 - val_loss: 3.0170\n",
            "Epoch 962/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8453 - val_loss: 3.0165\n",
            "Epoch 963/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 964/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 965/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 966/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 967/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 968/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 969/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 970/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8452 - val_loss: 3.0169\n",
            "Epoch 971/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8451 - val_loss: 3.0165\n",
            "Epoch 972/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 973/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 974/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 975/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 976/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 977/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 978/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 979/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 980/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 981/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 982/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 983/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 984/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 985/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 986/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 987/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 988/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 989/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 990/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8449 - val_loss: 3.0165\n",
            "Epoch 991/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 992/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 993/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 994/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8449 - val_loss: 3.0164\n",
            "Epoch 995/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 996/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 997/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "Epoch 998/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 999/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8450 - val_loss: 3.0165\n",
            "Epoch 1000/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8450 - val_loss: 3.0164\n",
            "{'loss': [8.993040084838867, 7.149789333343506, 4.854073524475098, 3.553590774536133, 3.408604145050049, 3.3393313884735107, 3.2348885536193848, 3.1727192401885986, 3.1229965686798096, 3.086120367050171, 3.0501322746276855, 3.0238730907440186, 3.0024847984313965, 2.984553337097168, 2.970245361328125, 2.9598546028137207, 2.9502477645874023, 2.9432785511016846, 2.9360804557800293, 2.929716110229492, 2.9245493412017822, 2.919954776763916, 2.9149608612060547, 2.909144401550293, 2.905665636062622, 2.9021949768066406, 2.8995702266693115, 2.8960745334625244, 2.8931546211242676, 2.8906586170196533, 2.888532876968384, 2.885781764984131, 2.883845090866089, 2.881765365600586, 2.880187511444092, 2.8780791759490967, 2.8767101764678955, 2.875108242034912, 2.8735878467559814, 2.872046709060669, 2.8707029819488525, 2.869492769241333, 2.868332862854004, 2.8672211170196533, 2.8662779331207275, 2.8651678562164307, 2.864258289337158, 2.8634355068206787, 2.862722396850586, 2.862125873565674, 2.861238479614258, 2.8605167865753174, 2.859952449798584, 2.8582887649536133, 2.857706069946289, 2.857128858566284, 2.8567020893096924, 2.8563766479492188, 2.855804443359375, 2.855222702026367, 2.854773759841919, 2.8545053005218506, 2.8540163040161133, 2.8536722660064697, 2.8534247875213623, 2.853137969970703, 2.8527653217315674, 2.852468967437744, 2.852170944213867, 2.851926565170288, 2.8517863750457764, 2.8514437675476074, 2.851212739944458, 2.850973129272461, 2.8508193492889404, 2.8506455421447754, 2.850522518157959, 2.8502683639526367, 2.8500750064849854, 2.8499767780303955, 2.8497226238250732, 2.8495614528656006, 2.849423408508301, 2.849321126937866, 2.849242687225342, 2.849099636077881, 2.848975419998169, 2.8487672805786133, 2.8487024307250977, 2.848494529724121, 2.8483998775482178, 2.8482933044433594, 2.8481671810150146, 2.848029851913452, 2.8479597568511963, 2.847850799560547, 2.8477461338043213, 2.8476500511169434, 2.8476202487945557, 2.8474762439727783, 2.8473923206329346, 2.8473012447357178, 2.8471977710723877, 2.847167491912842, 2.8470449447631836, 2.846951961517334, 2.8468964099884033, 2.8468143939971924, 2.84678053855896, 2.846663475036621, 2.8465631008148193, 2.8465018272399902, 2.8464229106903076, 2.8463847637176514, 2.846315860748291, 2.846268892288208, 2.8461616039276123, 2.8461198806762695, 2.8460705280303955, 2.8459982872009277, 2.845930814743042, 2.8458786010742188, 2.8458313941955566, 2.8457744121551514, 2.845738410949707, 2.845677375793457, 2.845625877380371, 2.8455679416656494, 2.8455495834350586, 2.8455023765563965, 2.8454530239105225, 2.8453900814056396, 2.8453476428985596, 2.845317840576172, 2.8452961444854736, 2.8452558517456055, 2.8452365398406982, 2.845172643661499, 2.8451313972473145, 2.845123291015625, 2.845061779022217, 2.8450379371643066, 2.845017433166504, 2.8449766635894775, 2.8449552059173584, 2.844911575317383, 2.8448634147644043, 2.8448259830474854, 2.8447978496551514, 2.8447768688201904, 2.844754695892334, 2.8447258472442627, 2.844714641571045, 2.8446731567382812, 2.8446617126464844, 2.8446428775787354, 2.8446054458618164, 2.8445847034454346, 2.8445630073547363, 2.844536066055298, 2.8445162773132324, 2.8445050716400146, 2.8444876670837402, 2.844468832015991, 2.844454288482666, 2.8444623947143555, 2.8444108963012695, 2.8443992137908936, 2.844379425048828, 2.8443658351898193, 2.8443470001220703, 2.8443360328674316, 2.844322681427002, 2.8443031311035156, 2.8442957401275635, 2.844275951385498, 2.8442676067352295, 2.8442537784576416, 2.844242572784424, 2.8442327976226807, 2.8442230224609375, 2.8442158699035645, 2.8442089557647705, 2.8441920280456543, 2.84419322013855, 2.8441972732543945, 2.8442037105560303, 2.8441638946533203, 2.844146251678467, 2.8441412448883057, 2.84413480758667, 2.8441286087036133, 2.8441364765167236, 2.844181537628174, 2.8442347049713135, 2.84427547454834, 2.8441104888916016, 2.8443477153778076, 2.8443219661712646, 2.844194173812866, 2.844088077545166, 2.844088077545166, 2.8440613746643066, 2.8440492153167725, 2.844055652618408, 2.844033718109131, 2.8440499305725098, 2.844043731689453, 2.844036102294922, 2.8440630435943604, 2.8441197872161865, 2.8440115451812744, 2.8441214561462402, 2.8441097736358643, 2.8450820446014404, 2.8444621562957764, 2.8454792499542236, 2.844127893447876, 2.8441267013549805, 2.843991994857788, 2.8440003395080566, 2.8440215587615967, 2.8444435596466064, 2.8440375328063965, 2.8440349102020264, 2.844632148742676, 2.8439905643463135, 2.843989133834839, 2.844017744064331, 2.844014883041382, 2.8439409732818604, 2.8439817428588867, 2.8439371585845947, 2.8439435958862305, 2.8439273834228516, 2.843931198120117, 2.8439223766326904, 2.8439197540283203, 2.843923807144165, 2.8439173698425293, 2.8439159393310547, 2.8439157009124756, 2.8439114093780518, 2.8439137935638428, 2.8439128398895264, 2.843909740447998, 2.8439104557037354, 2.8439056873321533, 2.843902111053467, 2.8439009189605713, 2.8438985347747803, 2.8438973426818848, 2.84389591217041, 2.8438937664031982, 2.8438937664031982, 2.8438918590545654, 2.8438916206359863, 2.8438901901245117, 2.8438897132873535, 2.843888282775879, 2.8438868522644043, 2.843885898590088, 2.8438854217529297, 2.8438849449157715, 2.8438827991485596, 2.8438827991485596, 2.8438832759857178, 2.8438804149627686, 2.8438796997070312, 2.843878984451294, 2.8438773155212402, 2.843879461288452, 2.8438773155212402, 2.843876838684082, 2.843874931335449, 2.84387469291687, 2.843873977661133, 2.8438727855682373, 2.8438730239868164, 2.8438735008239746, 2.8438708782196045, 2.8438711166381836, 2.84386944770813, 2.843869209289551, 2.843869209289551, 2.843869209289551, 2.843867540359497, 2.843867063522339, 2.8438661098480225, 2.8438661098480225, 2.8438656330108643, 2.843864917755127, 2.8438639640808105, 2.8438637256622314, 2.843863010406494, 2.843865394592285, 2.8438632488250732, 2.8438620567321777, 2.8438620567321777, 2.8438620567321777, 2.8438613414764404, 2.8438613414764404, 2.8438613414764404, 2.8438637256622314, 2.843862771987915, 2.8438589572906494, 2.8438594341278076, 2.8438589572906494, 2.843858480453491, 2.8438587188720703, 2.8438642024993896, 2.843858003616333, 2.8438572883605957, 2.8438565731048584, 2.8438563346862793, 2.843855381011963, 2.843855142593384, 2.843855142593384, 2.843855857849121, 2.843855381011963, 2.843855381011963, 2.8438541889190674, 2.843855619430542, 2.843862771987915, 2.8438613414764404, 2.843858242034912, 2.843871593475342, 2.843891143798828, 2.843916177749634, 2.843993902206421, 2.8441805839538574, 2.8441286087036133, 2.844499111175537, 2.844715118408203, 2.844947338104248, 2.844722032546997, 2.8444344997406006, 2.8442702293395996, 2.844221591949463, 2.8441293239593506, 2.8438796997070312, 2.8439595699310303, 2.844947576522827, 2.844947576522827, 2.8449432849884033, 2.8449432849884033, 2.844943046569824, 2.844942331314087, 2.844942569732666, 2.8449416160583496, 2.8449409008026123, 2.8449409008026123, 2.8449409008026123, 2.844940662384033, 2.8449409008026123, 2.844940662384033, 2.844940185546875, 2.844940185546875, 2.844940185546875, 2.844940423965454, 2.844940185546875, 2.844940185546875, 2.844939947128296, 2.8449394702911377, 2.844939947128296, 2.8449394702911377, 2.8449394702911377, 2.8449394702911377, 2.844939947128296, 2.844940185546875, 2.844940662384033, 2.8449416160583496, 2.844944953918457, 2.844942331314087, 2.8449392318725586, 2.8449387550354004, 2.8449387550354004, 2.8449385166168213, 2.8449385166168213, 2.8449394702911377, 2.8449394702911377, 2.8449394702911377, 2.8449394702911377, 2.844942808151245, 2.844940662384033, 2.844938278198242, 2.8449387550354004, 2.8449394702911377, 2.8449411392211914, 2.8449385166168213, 2.844940423965454, 2.8449463844299316, 2.84494686126709, 2.8449480533599854, 2.8449432849884033, 2.8449418544769287, 2.8449559211730957, 2.844954490661621, 2.8449387550354004, 2.8449389934539795, 2.8449418544769287, 2.8449482917785645, 2.8449630737304688, 2.8449535369873047, 2.8449437618255615, 2.8449392318725586, 2.844942331314087, 2.8449549674987793, 2.84496808052063, 2.8449785709381104, 2.8450567722320557, 2.8450074195861816, 2.8449387550354004, 2.844949722290039, 2.8449418544769287, 2.844940662384033, 2.8449442386627197, 2.8449463844299316, 2.8449387550354004, 2.844942569732666, 2.8449463844299316, 2.844939708709717, 2.844937324523926, 2.844937324523926, 2.8449370861053467, 2.844937801361084, 2.844938039779663, 2.844937562942505, 2.8449370861053467, 2.844937324523926, 2.844937562942505, 2.8449418544769287, 2.8449480533599854, 2.844973564147949, 2.8449838161468506, 2.845004081726074, 2.845067024230957, 2.8450286388397217, 2.844982147216797, 2.8449745178222656, 2.8450026512145996, 2.8451738357543945, 2.8452835083007812, 2.845043182373047, 2.8450050354003906, 2.844947099685669, 2.8449389934539795, 2.844938278198242, 2.844938039779663, 2.844938278198242, 2.8449392318725586, 2.844966411590576, 2.845155954360962, 2.845101833343506, 2.845061779022217, 2.844984769821167, 2.8449583053588867, 2.8449418544769287, 2.8449456691741943, 2.8449604511260986, 2.8449459075927734, 2.8449456691741943, 2.844968318939209, 2.845001220703125, 2.8450911045074463, 2.8452484607696533, 2.8449883460998535, 2.845180034637451, 2.8450987339019775, 2.844954490661621, 2.844956636428833, 2.8449459075927734, 2.8449392318725586, 2.8449385166168213, 2.844937801361084, 2.844937562942505, 2.8449385166168213, 2.8449418544769287, 2.8449532985687256, 2.844977378845215, 2.845012664794922, 2.8450047969818115, 2.8450260162353516, 2.845118522644043, 2.8450961112976074, 2.8450217247009277, 2.8450605869293213, 2.8451087474823, 2.845062255859375, 2.845001220703125, 2.844970226287842, 2.844973564147949, 2.8450684547424316, 2.845452308654785, 2.8455164432525635, 2.84512996673584, 2.8450441360473633, 2.8449654579162598, 2.844963788986206, 2.8449552059173584, 2.8449463844299316, 2.844944953918457, 2.8449418544769287, 2.8449385166168213, 2.844937324523926, 2.8449370861053467, 2.8449366092681885, 2.8449366092681885, 2.8449363708496094, 2.8449368476867676, 2.8449368476867676, 2.8449370861053467, 2.844937324523926, 2.844937562942505, 2.8449409008026123, 2.844937801361084, 2.844937801361084, 2.844939708709717, 2.8449442386627197, 2.8449556827545166, 2.8449394702911377, 2.8449602127075195, 2.84501576423645, 2.8451035022735596, 2.844959259033203, 2.845142126083374, 2.8452370166778564, 2.8450264930725098, 2.8449606895446777, 2.8450076580047607, 2.8449947834014893, 2.844973087310791, 2.8450255393981934, 2.844984531402588, 2.844979763031006, 2.8449900150299072, 2.844992160797119, 2.8449840545654297, 2.8449528217315674, 2.844949722290039, 2.8450019359588623, 2.845121145248413, 2.845160961151123, 2.845062017440796, 2.8450429439544678, 2.8450307846069336, 2.844970226287842, 2.8451437950134277, 2.845304012298584, 2.845348834991455, 2.8452577590942383, 2.845001697540283, 2.845080852508545, 2.845041036605835, 2.8449854850769043, 2.845100164413452, 2.844974994659424, 2.844961643218994, 2.8449623584747314, 2.844977378845215, 2.8450124263763428, 2.844959020614624, 2.8449740409851074, 2.845029830932617, 2.8450796604156494, 2.845216989517212, 2.84576416015625, 2.8453643321990967, 2.8449811935424805, 2.844994068145752, 2.844958782196045, 2.8449454307556152, 2.844952344894409, 2.8449418544769287, 2.8449535369873047, 2.8449513912200928, 2.8449504375457764, 2.844951868057251, 2.844987392425537, 2.845161199569702, 2.8449513912200928, 2.844947576522827, 2.844947338104248, 2.844954490661621, 2.844956159591675, 2.844954252243042, 2.844953775405884, 2.8449885845184326, 2.8457672595977783, 2.8456637859344482, 2.8454220294952393, 2.8450868129730225, 2.845184803009033, 2.845250368118286, 2.845292806625366, 2.845182180404663, 2.8450043201446533, 2.8449783325195312, 2.8449628353118896, 2.844954252243042, 2.8449504375457764, 2.844947576522827, 2.844947338104248, 2.8449478149414062, 2.844949960708618, 2.8449530601501465, 2.844949722290039, 2.8449504375457764, 2.8449480533599854, 2.8449478149414062, 2.844947338104248, 2.8449480533599854, 2.844947576522827, 2.8449480533599854, 2.8449480533599854, 2.844947338104248, 2.844947338104248, 2.8449480533599854, 2.8449480533599854, 2.8449482917785645, 2.844951629638672, 2.844966411590576, 2.8449504375457764, 2.844954490661621, 2.8449549674987793, 2.8449831008911133, 2.844994068145752, 2.8449976444244385, 2.8451077938079834, 2.8450138568878174, 2.845001459121704, 2.8450493812561035, 2.845120429992676, 2.845374584197998, 2.8452820777893066, 2.845029830932617, 2.8449859619140625, 2.844996690750122, 2.8449931144714355, 2.8450827598571777, 2.8451180458068848, 2.8451178073883057, 2.845168352127075, 2.8455235958099365, 2.8458030223846436, 2.8460400104522705, 2.847050428390503, 2.8468947410583496, 2.8453705310821533, 2.8456504344940186, 2.8451039791107178, 2.845048427581787, 2.8449881076812744, 2.844968795776367, 2.8449530601501465, 2.844949245452881, 2.8449480533599854, 2.844947338104248, 2.844947338104248, 2.8449482917785645, 2.8449487686157227, 2.844947576522827, 2.8449478149414062, 2.844949245452881, 2.8449501991271973, 2.84495210647583, 2.8449652194976807, 2.8449671268463135, 2.844952344894409, 2.8449480533599854, 2.844947338104248, 2.844947338104248, 2.8449509143829346, 2.8449549674987793, 2.844963312149048, 2.844970941543579, 2.8450207710266113, 2.8451035022735596, 2.84507417678833, 2.8451242446899414, 2.845259428024292, 2.8450229167938232, 2.8453752994537354, 2.84533429145813, 2.8450257778167725, 2.8452184200286865, 2.8450417518615723, 2.8449671268463135, 2.844986915588379, 2.844961166381836, 2.844963312149048, 2.8449532985687256, 2.8449490070343018, 2.844947576522827, 2.844947338104248, 2.844947099685669, 2.844947338104248, 2.844947099685669, 2.844947099685669, 2.844947338104248, 2.844947576522827, 2.844947576522827, 2.844949722290039, 2.844954013824463, 2.8449981212615967, 2.845038414001465, 2.8457071781158447, 2.8452188968658447, 2.845021963119507, 2.8449645042419434, 2.844951868057251, 2.84495210647583, 2.8449559211730957, 2.8449547290802, 2.8449482917785645, 2.8449487686157227, 2.8449482917785645, 2.8449504375457764, 2.8449559211730957, 2.8449630737304688, 2.844966411590576, 2.8449833393096924, 2.845029592514038, 2.8451168537139893, 2.845289707183838, 2.8453104496002197, 2.845175266265869, 2.844972848892212, 2.8449981212615967, 2.844977378845215, 2.844953775405884, 2.844951629638672, 2.84494948387146, 2.8449478149414062, 2.844947338104248, 2.84494686126709, 2.8449466228485107, 2.84494686126709, 2.84494686126709, 2.84494686126709, 2.844947099685669, 2.84494686126709, 2.84494686126709, 2.844947338104248, 2.8449466228485107, 2.84494686126709, 2.84494686126709, 2.84494686126709, 2.844947099685669, 2.844947338104248, 2.84494686126709, 2.84494686126709, 2.84494686126709, 2.844947099685669, 2.844947338104248, 2.8449466228485107, 2.844947099685669, 2.844947099685669, 2.84494686126709, 2.84494686126709, 2.8449466228485107, 2.8449466228485107, 2.8449466228485107, 2.84494686126709, 2.8449466228485107, 2.84494686126709, 2.84494686126709, 2.84494686126709, 2.84494686126709, 2.84494686126709, 2.84494686126709, 2.844947099685669, 2.84494686126709, 2.844947099685669, 2.844947099685669, 2.84494686126709, 2.844947099685669, 2.84494686126709, 2.84494686126709, 2.84494686126709, 2.84494686126709, 2.84494686126709, 2.84494686126709, 2.84494686126709, 2.84494686126709, 2.844947338104248, 2.844947099685669, 2.844947338104248, 2.8449480533599854, 2.844949245452881, 2.8449645042419434, 2.845611333847046, 2.8460566997528076, 2.8458104133605957, 2.84531831741333, 2.845228433609009, 2.8450586795806885, 2.8450124263763428, 2.8449604511260986, 2.8449599742889404, 2.8449573516845703, 2.8449530601501465, 2.8449692726135254, 2.845015525817871, 2.844973564147949, 2.8449759483337402, 2.845078945159912, 2.845243453979492, 2.8456051349639893, 2.8455846309661865, 2.845811605453491, 2.845594882965088, 2.8452835083007812, 2.8451220989227295, 2.845097064971924, 2.8450112342834473, 2.8450260162353516, 2.845036029815674, 2.8450663089752197, 2.8449935913085938, 2.84525728225708, 2.8467752933502197, 2.8452088832855225, 2.845386028289795, 2.8450348377227783, 2.8449978828430176, 2.844984531402588, 2.84498929977417, 2.8449714183807373, 2.8449795246124268, 2.8449840545654297, 2.8449625968933105, 2.8449671268463135, 2.844964027404785, 2.8449513912200928, 2.84494948387146, 2.8449490070343018, 2.844951868057251, 2.8449814319610596, 2.8450217247009277, 2.844979763031006, 2.8449971675872803, 2.8450281620025635, 2.8452141284942627, 2.84531569480896, 2.8451499938964844, 2.8450043201446533, 2.844963788986206, 2.8449783325195312, 2.8449625968933105, 2.8449790477752686, 2.8449819087982178, 2.844970226287842, 2.8449628353118896, 2.8449673652648926, 2.8449783325195312, 2.844954252243042, 2.845015287399292, 2.8449718952178955, 2.8450369834899902, 2.8450663089752197, 2.8450303077697754, 2.8449623584747314, 2.8450205326080322, 2.8449721336364746, 2.844954252243042, 2.8449654579162598, 2.844970703125, 2.844968557357788, 2.8449931144714355, 2.8449695110321045, 2.844982385635376, 2.844980478286743, 2.844984531402588, 2.8449532985687256, 2.8449528217315674, 2.8449506759643555, 2.8449480533599854, 2.844947576522827, 2.844947338104248, 2.844947576522827, 2.844947576522827, 2.8449490070343018, 2.8449580669403076, 2.8449623584747314, 2.8450028896331787, 2.8450162410736084, 2.8449957370758057, 2.844992160797119, 2.845006227493286, 2.8449742794036865, 2.844970703125, 2.8449580669403076, 2.8449513912200928, 2.8449501991271973, 2.844954013824463, 2.8449621200561523, 2.845024585723877, 2.8452391624450684, 2.8462183475494385, 2.846068859100342, 2.8462934494018555, 2.845712184906006, 2.8453009128570557, 2.8457343578338623, 2.845261812210083, 2.8451709747314453, 2.8450472354888916, 2.8450067043304443, 2.8449814319610596, 2.8449559211730957, 2.84495210647583, 2.844949722290039, 2.8449480533599854, 2.844947338104248, 2.8449466228485107, 2.84494686126709, 2.844947099685669, 2.84494686126709, 2.84494686126709, 2.844947338104248, 2.84494686126709, 2.84494686126709, 2.84494686126709, 2.84494686126709, 2.844947338104248, 2.8449478149414062, 2.844947338104248, 2.8449513912200928, 2.8449642658233643, 2.8449819087982178, 2.8449759483337402, 2.8449766635894775, 2.845017194747925, 2.845202922821045, 2.8454172611236572, 2.845348596572876, 2.845259189605713, 2.845179319381714, 2.845109701156616, 2.8450534343719482, 2.8450331687927246, 2.8450257778167725, 2.8451106548309326, 2.8449931144714355, 2.8449857234954834, 2.8449811935424805, 2.8450005054473877, 2.845008373260498, 2.844982147216797, 2.8449654579162598, 2.8449532985687256, 2.844956874847412, 2.8449668884277344, 2.844952344894409, 2.84496808052063, 2.8449583053588867, 2.8450276851654053, 2.8451240062713623, 2.845365285873413, 2.8456671237945557, 2.8453428745269775, 2.8450422286987305, 2.844974994659424, 2.844971179962158, 2.844956874847412, 2.844956159591675, 2.8449490070343018, 2.8449580669403076, 2.8451883792877197, 2.8450567722320557, 2.8449954986572266, 2.844966411590576, 2.844956636428833, 2.8449556827545166, 2.84495210647583, 2.844963312149048, 2.844963788986206, 2.844956159591675, 2.84495210647583, 2.8449509143829346, 2.8449504375457764, 2.8449482917785645, 2.8449482917785645, 2.84494948387146, 2.844949245452881, 2.8449480533599854, 2.8449478149414062, 2.844947576522827, 2.8449478149414062, 2.844951868057251, 2.8449625968933105, 2.8449506759643555, 2.8449482917785645, 2.84495210647583, 2.8449530601501465, 2.8449575901031494, 2.8449630737304688, 2.845001459121704, 2.8449923992156982], 'val_loss': [8.1450834274292, 6.0713677406311035, 4.0696635246276855, 3.643712043762207, 3.626152753829956, 3.530596971511841, 3.4680440425872803, 3.4284145832061768, 3.3924901485443115, 3.371278762817383, 3.3517982959747314, 3.337322950363159, 3.3263304233551025, 3.3185207843780518, 3.3129663467407227, 3.3102681636810303, 3.30690598487854, 3.306426525115967, 3.305236577987671, 3.304224967956543, 3.303783893585205, 3.3027124404907227, 3.3015143871307373, 3.30196475982666, 3.3013739585876465, 3.2998509407043457, 3.2984726428985596, 3.2970871925354004, 3.2978994846343994, 3.2974853515625, 3.2971107959747314, 3.2966055870056152, 3.295663833618164, 3.295440435409546, 3.2958412170410156, 3.295154094696045, 3.2956008911132812, 3.2956743240356445, 3.295264482498169, 3.295583724975586, 3.2956442832946777, 3.2952640056610107, 3.295058012008667, 3.295537233352661, 3.294646739959717, 3.2945520877838135, 3.29423189163208, 3.294461727142334, 3.29506254196167, 3.294769525527954, 3.294934034347534, 3.2944180965423584, 3.29481840133667, 3.2946207523345947, 3.2944302558898926, 3.2943129539489746, 3.2948009967803955, 3.2954673767089844, 3.294569492340088, 3.2943918704986572, 3.2949397563934326, 3.295207977294922, 3.295447826385498, 3.2956082820892334, 3.295459747314453, 3.2954068183898926, 3.295314311981201, 3.2957699298858643, 3.2959530353546143, 3.29618239402771, 3.295001983642578, 3.29439115524292, 3.294673442840576, 3.2944753170013428, 3.294499635696411, 3.294529914855957, 3.2948968410491943, 3.294740915298462, 3.2947328090667725, 3.2950239181518555, 3.2946996688842773, 3.2946743965148926, 3.2941906452178955, 3.2929584980010986, 3.2925195693969727, 3.2920784950256348, 3.291961431503296, 3.2907798290252686, 3.2900538444519043, 3.2895267009735107, 3.289095401763916, 3.288686990737915, 3.2881574630737305, 3.287475824356079, 3.2865757942199707, 3.2857089042663574, 3.284656524658203, 3.283898115158081, 3.2832536697387695, 3.282585382461548, 3.281672954559326, 3.2809667587280273, 3.2800281047821045, 3.279440402984619, 3.2783119678497314, 3.2777976989746094, 3.276571750640869, 3.2759299278259277, 3.2750585079193115, 3.273987293243408, 3.2724668979644775, 3.271657943725586, 3.2705726623535156, 3.269758939743042, 3.2684741020202637, 3.2668850421905518, 3.265944719314575, 3.2647757530212402, 3.263413190841675, 3.262195587158203, 3.260875701904297, 3.2595183849334717, 3.258432149887085, 3.257096767425537, 3.255876064300537, 3.2544541358947754, 3.2529709339141846, 3.2516374588012695, 3.250440835952759, 3.249037027359009, 3.2477054595947266, 3.2463676929473877, 3.24507212638855, 3.243323802947998, 3.2419445514678955, 3.2404944896698, 3.2389378547668457, 3.237597703933716, 3.236304759979248, 3.234816789627075, 3.233360528945923, 3.231843948364258, 3.230384111404419, 3.229158878326416, 3.227583646774292, 3.226006031036377, 3.22468900680542, 3.223158597946167, 3.221635580062866, 3.220078945159912, 3.2184970378875732, 3.2170932292938232, 3.2154364585876465, 3.2140581607818604, 3.2125275135040283, 3.211007595062256, 3.2093770503997803, 3.207815408706665, 3.2064263820648193, 3.2050652503967285, 3.2034950256347656, 3.201939821243286, 3.2004776000976562, 3.198899745941162, 3.1973979473114014, 3.1961143016815186, 3.194610118865967, 3.1931464672088623, 3.1916630268096924, 3.190338373184204, 3.1889219284057617, 3.1875994205474854, 3.186079978942871, 3.1847281455993652, 3.183257579803467, 3.181760549545288, 3.1803629398345947, 3.179003953933716, 3.177635669708252, 3.1762661933898926, 3.174962043762207, 3.173685073852539, 3.172236204147339, 3.1710193157196045, 3.1695940494537354, 3.168391704559326, 3.1669864654541016, 3.165834665298462, 3.16458797454834, 3.163022756576538, 3.1617612838745117, 3.1602821350097656, 3.159395694732666, 3.157883644104004, 3.1567442417144775, 3.155791759490967, 3.153881072998047, 3.153672695159912, 3.1517674922943115, 3.1504170894622803, 3.1495816707611084, 3.1482772827148438, 3.1472036838531494, 3.1460001468658447, 3.144913911819458, 3.143623113632202, 3.1426897048950195, 3.141576051712036, 3.140465021133423, 3.139451503753662, 3.1384832859039307, 3.137427806854248, 3.136434555053711, 3.135707378387451, 3.1346888542175293, 3.133711576461792, 3.1325204372406006, 3.131418228149414, 3.1304094791412354, 3.129472017288208, 3.1286158561706543, 3.127769708633423, 3.1268880367279053, 3.1260058879852295, 3.1253843307495117, 3.1241261959075928, 3.1234118938446045, 3.1224524974823, 3.121675491333008, 3.1207737922668457, 3.120006561279297, 3.11920166015625, 3.1185178756713867, 3.117781162261963, 3.1170241832733154, 3.116269826889038, 3.1155683994293213, 3.1148014068603516, 3.114006996154785, 3.1132054328918457, 3.112297534942627, 3.1114096641540527, 3.1104862689971924, 3.109480619430542, 3.1086223125457764, 3.1076700687408447, 3.106764793395996, 3.105889320373535, 3.104952096939087, 3.1040420532226562, 3.103116512298584, 3.102180004119873, 3.1014139652252197, 3.1005399227142334, 3.099656105041504, 3.0988364219665527, 3.097957134246826, 3.0970442295074463, 3.096252918243408, 3.0954487323760986, 3.094667673110962, 3.093834161758423, 3.0930235385894775, 3.0922765731811523, 3.0914578437805176, 3.0906944274902344, 3.0898587703704834, 3.089094877243042, 3.0882952213287354, 3.0875346660614014, 3.0867645740509033, 3.0860068798065186, 3.0852839946746826, 3.0845699310302734, 3.0838534832000732, 3.0830743312835693, 3.0823755264282227, 3.081686496734619, 3.0809848308563232, 3.0802314281463623, 3.079582929611206, 3.0788581371307373, 3.078183650970459, 3.077528953552246, 3.0768730640411377, 3.0762202739715576, 3.0755369663238525, 3.074882984161377, 3.0743000507354736, 3.073716640472412, 3.073077440261841, 3.0724642276763916, 3.0717504024505615, 3.0711617469787598, 3.0705103874206543, 3.0700113773345947, 3.0692195892333984, 3.0687100887298584, 3.0681838989257812, 3.067664861679077, 3.0671591758728027, 3.066627264022827, 3.065995454788208, 3.065462112426758, 3.0647904872894287, 3.064347267150879, 3.0637729167938232, 3.06321382522583, 3.0626754760742188, 3.062131881713867, 3.0618669986724854, 3.0613739490509033, 3.0608482360839844, 3.0602807998657227, 3.059779644012451, 3.0592761039733887, 3.0587825775146484, 3.058317184448242, 3.057892084121704, 3.057344913482666, 3.056915283203125, 3.056485652923584, 3.056039333343506, 3.0556530952453613, 3.055006504058838, 3.0548160076141357, 3.054255485534668, 3.054237127304077, 3.0533413887023926, 3.0539956092834473, 3.0536763668060303, 3.0518546104431152, 3.0524206161499023, 3.056077480316162, 3.055551290512085, 3.055619478225708, 3.05556321144104, 3.0550427436828613, 3.054070234298706, 3.0525875091552734, 3.0532686710357666, 3.0536694526672363, 3.053560733795166, 3.0531933307647705, 3.0528581142425537, 3.052438735961914, 3.0521390438079834, 3.051689624786377, 3.051356315612793, 3.0509533882141113, 3.0505895614624023, 3.0502688884735107, 3.0499496459960938, 3.0496115684509277, 3.0492665767669678, 3.0489513874053955, 3.048649311065674, 3.0483298301696777, 3.0480782985687256, 3.047769546508789, 3.0474605560302734, 3.0471651554107666, 3.0468332767486572, 3.046560525894165, 3.0462663173675537, 3.045942783355713, 3.0456807613372803, 3.0454390048980713, 3.0451996326446533, 3.0449416637420654, 3.044670581817627, 3.0444724559783936, 3.0442121028900146, 3.0439634323120117, 3.043729305267334, 3.043466329574585, 3.0432519912719727, 3.0430474281311035, 3.042800188064575, 3.0425562858581543, 3.042332649230957, 3.0421159267425537, 3.0419623851776123, 3.041757345199585, 3.0415115356445312, 3.0413293838500977, 3.041158676147461, 3.0409295558929443, 3.0407397747039795, 3.040534019470215, 3.0403597354888916, 3.040166139602661, 3.0400171279907227, 3.039851665496826, 3.0396642684936523, 3.039489269256592, 3.0392816066741943, 3.0390806198120117, 3.0388996601104736, 3.0387494564056396, 3.0385637283325195, 3.0383784770965576, 3.038233518600464, 3.038022756576538, 3.0378739833831787, 3.037734270095825, 3.0375430583953857, 3.037396192550659, 3.0372650623321533, 3.037106990814209, 3.036914110183716, 3.0367469787597656, 3.0365841388702393, 3.036426067352295, 3.0362560749053955, 3.036109685897827, 3.035973310470581, 3.035810708999634, 3.035658359527588, 3.0355005264282227, 3.0353758335113525, 3.0352556705474854, 3.035088062286377, 3.0349228382110596, 3.034778594970703, 3.0346322059631348, 3.0344834327697754, 3.034346342086792, 3.034219741821289, 3.034072160720825, 3.033914089202881, 3.033799171447754, 3.033665180206299, 3.0335593223571777, 3.0334043502807617, 3.0334460735321045, 3.0333218574523926, 3.0331320762634277, 3.0329489707946777, 3.032805919647217, 3.0326688289642334, 3.0326120853424072, 3.0325498580932617, 3.0323197841644287, 3.0321226119995117, 3.032013416290283, 3.0319159030914307, 3.0317747592926025, 3.0316481590270996, 3.0315427780151367, 3.031420946121216, 3.0313339233398438, 3.031527042388916, 3.0314247608184814, 3.0311410427093506, 3.0309150218963623, 3.0308189392089844, 3.0306832790374756, 3.0305235385894775, 3.0303878784179688, 3.0302822589874268, 3.030176877975464, 3.0300726890563965, 3.0299718379974365, 3.0298497676849365, 3.0297927856445312, 3.0297060012817383, 3.029550313949585, 3.0294535160064697, 3.02931809425354, 3.029223680496216, 3.029114007949829, 3.029024362564087, 3.0289323329925537, 3.0288403034210205, 3.028707504272461, 3.028635025024414, 3.0284886360168457, 3.028473138809204, 3.02830171585083, 3.0283761024475098, 3.0281336307525635, 3.0282444953918457, 3.0279288291931152, 3.0280168056488037, 3.027782917022705, 3.0276989936828613, 3.0276296138763428, 3.027493476867676, 3.027434825897217, 3.027298927307129, 3.0273663997650146, 3.027259349822998, 3.0275769233703613, 3.027287483215332, 3.0269577503204346, 3.026808261871338, 3.026747703552246, 3.0266809463500977, 3.0266225337982178, 3.026562213897705, 3.0265238285064697, 3.02644419670105, 3.0263688564300537, 3.0262951850891113, 3.0262205600738525, 3.02614688873291, 3.0260839462280273, 3.0260112285614014, 3.025918483734131, 3.0258398056030273, 3.0257585048675537, 3.0256874561309814, 3.025637626647949, 3.0256011486053467, 3.0255560874938965, 3.0254693031311035, 3.025442361831665, 3.025346279144287, 3.025294780731201, 3.0252938270568848, 3.025189161300659, 3.025125503540039, 3.0251193046569824, 3.0249204635620117, 3.025179147720337, 3.0248594284057617, 3.024796962738037, 3.0249276161193848, 3.0248160362243652, 3.0247340202331543, 3.024876594543457, 3.0246222019195557, 3.0245072841644287, 3.0246646404266357, 3.024712085723877, 3.0247888565063477, 3.0244996547698975, 3.0244250297546387, 3.024453639984131, 3.0241341590881348, 3.0242671966552734, 3.0241501331329346, 3.0239813327789307, 3.0238490104675293, 3.0236711502075195, 3.0236926078796387, 3.023466110229492, 3.023740291595459, 3.023416519165039, 3.0233476161956787, 3.023390293121338, 3.0230696201324463, 3.023008346557617, 3.023092746734619, 3.022871494293213, 3.022860050201416, 3.022728681564331, 3.0227153301239014, 3.0224785804748535, 3.022402763366699, 3.022400379180908, 3.0222387313842773, 3.022353172302246, 3.022573709487915, 3.022033214569092, 3.022416114807129, 3.0219154357910156, 3.0217278003692627, 3.0218756198883057, 3.0217697620391846, 3.0215299129486084, 3.0215446949005127, 3.0215530395507812, 3.021385431289673, 3.0213046073913574, 3.0212960243225098, 3.021228790283203, 3.021153688430786, 3.021103858947754, 3.021028995513916, 3.0209712982177734, 3.020920753479004, 3.0208613872528076, 3.020807981491089, 3.0207393169403076, 3.0206830501556396, 3.0206284523010254, 3.0205836296081543, 3.0206851959228516, 3.0204973220825195, 3.0204238891601562, 3.0205025672912598, 3.0209767818450928, 3.020676374435425, 3.0204741954803467, 3.0203890800476074, 3.020266056060791, 3.0201878547668457, 3.020108938217163, 3.020034074783325, 3.019946336746216, 3.019882917404175, 3.0198237895965576, 3.019766330718994, 3.019707202911377, 3.019655227661133, 3.019599676132202, 3.0195424556732178, 3.019500970840454, 3.019451856613159, 3.019399642944336, 3.019357442855835, 3.019313335418701, 3.019258737564087, 3.0192136764526367, 3.019164562225342, 3.0191221237182617, 3.0190720558166504, 3.019036054611206, 3.019010543823242, 3.018951177597046, 3.0189077854156494, 3.0188636779785156, 3.0188510417938232, 3.018798351287842, 3.018777370452881, 3.018770456314087, 3.0187528133392334, 3.018709421157837, 3.018622875213623, 3.018705368041992, 3.018731117248535, 3.018772602081299, 3.0185189247131348, 3.0185587406158447, 3.0184555053710938, 3.018455982208252, 3.0184829235076904, 3.0183770656585693, 3.018353223800659, 3.0183417797088623, 3.0186572074890137, 3.018979787826538, 3.0184216499328613, 3.0202934741973877, 3.0193984508514404, 3.018800973892212, 3.018418073654175, 3.018439769744873, 3.01857590675354, 3.0183236598968506, 3.0181477069854736, 3.0181188583374023, 3.0181360244750977, 3.018099308013916, 3.018044948577881, 3.0180137157440186, 3.0179824829101562, 3.0179531574249268, 3.0179202556610107, 3.0178849697113037, 3.017857551574707, 3.017829418182373, 3.0178072452545166, 3.017780303955078, 3.017773151397705, 3.017731189727783, 3.017706871032715, 3.0176751613616943, 3.017651081085205, 3.0176286697387695, 3.017612934112549, 3.0175881385803223, 3.0175669193267822, 3.0175623893737793, 3.017636299133301, 3.0175178050994873, 3.0175602436065674, 3.017622470855713, 3.017529010772705, 3.017533779144287, 3.0174505710601807, 3.017514705657959, 3.017479658126831, 3.0173864364624023, 3.017362117767334, 3.017320394515991, 3.0173158645629883, 3.01729679107666, 3.017265796661377, 3.0172479152679443, 3.0172295570373535, 3.017216205596924, 3.017204761505127, 3.01719069480896, 3.0171754360198975, 3.0171616077423096, 3.0171444416046143, 3.0171351432800293, 3.0171196460723877, 3.017117500305176, 3.0170986652374268, 3.0170562267303467, 3.017129898071289, 3.0174930095672607, 3.0170810222625732, 3.017096519470215, 3.016977071762085, 3.0169894695281982, 3.017010450363159, 3.0169763565063477, 3.0169851779937744, 3.0169529914855957, 3.0169427394866943, 3.01693058013916, 3.0169222354888916, 3.0169029235839844, 3.016897201538086, 3.016885757446289, 3.016869306564331, 3.016869068145752, 3.0168612003326416, 3.0173861980438232, 3.0168938636779785, 3.016955614089966, 3.016887664794922, 3.016859292984009, 3.0168819427490234, 3.0168209075927734, 3.016806125640869, 3.016805648803711, 3.0167956352233887, 3.016787052154541, 3.0167815685272217, 3.0167717933654785, 3.0167629718780518, 3.016756057739258, 3.0167481899261475, 3.0167412757873535, 3.0167315006256104, 3.0167253017425537, 3.0167181491851807, 3.016710042953491, 3.016702651977539, 3.0166971683502197, 3.016690254211426, 3.016684055328369, 3.0166783332824707, 3.016672134399414, 3.0166664123535156, 3.016660451889038, 3.016653537750244, 3.016648054122925, 3.01664137840271, 3.016637086868286, 3.016631841659546, 3.0166268348693848, 3.0166213512420654, 3.0166170597076416, 3.0166120529174805, 3.0166072845458984, 3.0166022777557373, 3.0165982246398926, 3.0165932178497314, 3.0165889263153076, 3.016584873199463, 3.016580581665039, 3.0165767669677734, 3.0165727138519287, 3.016568899154663, 3.016564130783081, 3.0165600776672363, 3.0165584087371826, 3.016554832458496, 3.0165510177612305, 3.016547918319702, 3.0165441036224365, 3.016541004180908, 3.016538143157959, 3.0165348052978516, 3.0165319442749023, 3.016528367996216, 3.0165250301361084, 3.01652193069458, 3.0165188312530518, 3.01651668548584, 3.0165154933929443, 3.0165157318115234, 3.0165224075317383, 3.016868829727173, 3.0180089473724365, 3.017737627029419, 3.0169806480407715, 3.016930103302002, 3.0166449546813965, 3.0167253017425537, 3.0166192054748535, 3.016659736633301, 3.0166585445404053, 3.0166516304016113, 3.0166432857513428, 3.0166518688201904, 3.0166592597961426, 3.0166356563568115, 3.0166821479797363, 3.0166890621185303, 3.0169997215270996, 3.017042875289917, 3.0167031288146973, 3.0169379711151123, 3.0166754722595215, 3.0166165828704834, 3.0166640281677246, 3.0166385173797607, 3.016555070877075, 3.0165810585021973, 3.0165598392486572, 3.016568660736084, 3.0166170597076416, 3.017183303833008, 3.0167269706726074, 3.016867160797119, 3.0165443420410156, 3.016536235809326, 3.0165512561798096, 3.016526699066162, 3.0165011882781982, 3.016477584838867, 3.016467571258545, 3.0164666175842285, 3.016464948654175, 3.0164730548858643, 3.016463279724121, 3.0164573192596436, 3.016458511352539, 3.016453742980957, 3.016514778137207, 3.016566753387451, 3.0165023803710938, 3.0165107250213623, 3.0164878368377686, 3.0165159702301025, 3.016761064529419, 3.0165905952453613, 3.016524076461792, 3.016465425491333, 3.0164523124694824, 3.0164730548858643, 3.0164635181427, 3.016494035720825, 3.016479969024658, 3.016462564468384, 3.016465663909912, 3.0164756774902344, 3.0164647102355957, 3.0164620876312256, 3.0164761543273926, 3.0164897441864014, 3.0164763927459717, 3.0165107250213623, 3.0164425373077393, 3.0164809226989746, 3.0164453983306885, 3.016444206237793, 3.0164501667022705, 3.016447067260742, 3.0164406299591064, 3.0164544582366943, 3.0164613723754883, 3.016444683074951, 3.016441583633423, 3.0164384841918945, 3.016436815261841, 3.0164406299591064, 3.01643967628479, 3.016432762145996, 3.016432046890259, 3.0164313316345215, 3.0164315700531006, 3.0164315700531006, 3.0164315700531006, 3.016434669494629, 3.0164482593536377, 3.01645827293396, 3.0166194438934326, 3.016572952270508, 3.0165178775787354, 3.016496181488037, 3.0164568424224854, 3.0164849758148193, 3.016448736190796, 3.016442060470581, 3.0164358615875244, 3.0164363384246826, 3.0164382457733154, 3.0164361000061035, 3.016526699066162, 3.017638683319092, 3.0181684494018555, 3.018287181854248, 3.016587018966675, 3.017230272293091, 3.0165481567382812, 3.016866683959961, 3.01688289642334, 3.0166566371917725, 3.0165164470672607, 3.016491413116455, 3.016427993774414, 3.0164260864257812, 3.016425848007202, 3.0164272785186768, 3.0164260864257812, 3.0164272785186768, 3.0164284706115723, 3.0164289474487305, 3.0164296627044678, 3.0164308547973633, 3.0164315700531006, 3.016432762145996, 3.0164339542388916, 3.016435146331787, 3.016436815261841, 3.0164382457733154, 3.0164382457733154, 3.016439914703369, 3.01644229888916, 3.016453266143799, 3.016463041305542, 3.0164613723754883, 3.016474485397339, 3.016481637954712, 3.0165703296661377, 3.0167462825775146, 3.0167222023010254, 3.0165650844573975, 3.016484498977661, 3.0167970657348633, 3.016660451889038, 3.016583204269409, 3.0166175365448, 3.0166358947753906, 3.0165812969207764, 3.016615390777588, 3.016533613204956, 3.016507148742676, 3.0165822505950928, 3.0165371894836426, 3.016479253768921, 3.0164787769317627, 3.0164711475372314, 3.0164761543273926, 3.0164668560028076, 3.0164573192596436, 3.016456127166748, 3.0164577960968018, 3.01650333404541, 3.0165581703186035, 3.016618490219116, 3.0170323848724365, 3.016486406326294, 3.016493797302246, 3.016493320465088, 3.0164546966552734, 3.016472816467285, 3.016448736190796, 3.016451835632324, 3.0164504051208496, 3.016901731491089, 3.0164666175842285, 3.0164735317230225, 3.016512870788574, 3.0164902210235596, 3.0164694786071777, 3.0164921283721924, 3.0164802074432373, 3.0164685249328613, 3.0164692401885986, 3.0164589881896973, 3.0164668560028076, 3.016453742980957, 3.0164475440979004, 3.016446828842163, 3.0164453983306885, 3.0164477825164795, 3.0164456367492676, 3.0164482593536377, 3.0164482593536377, 3.0164525508880615, 3.0164554119110107, 3.016462564468384, 3.016453742980957, 3.0164456367492676, 3.0164456367492676, 3.016444206237793, 3.0164473056793213, 3.0164706707000732, 3.0164921283721924, 3.0164413452148438]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = autoencoder.predict(data2)"
      ],
      "metadata": {
        "id": "o3SVx6k1bwob"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(predictions)"
      ],
      "metadata": {
        "id": "t5CjYaDkyw9u"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "J7QMCE8bymTR",
        "outputId": "198f1651-8990-4381-ed2d-a43bdcbcb355"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0         1    2    3         4    5         6    7          8   \\\n",
              "0    0.0  0.999975  0.0  0.0  2.999971  0.0  1.999995  0.0   6.000001   \n",
              "1    0.0  2.999948  0.0  0.0  2.000023  0.0  0.999994  0.0   3.000013   \n",
              "2    0.0  1.999930  0.0  0.0  1.000061  0.0  0.999996  0.0   3.000026   \n",
              "3    0.0  2.999974  0.0  0.0  1.999988  0.0  2.000005  0.0   5.000000   \n",
              "4    0.0  0.999969  0.0  0.0  3.000021  0.0  1.999999  0.0   8.000015   \n",
              "..   ...       ...  ...  ...       ...  ...       ...  ...        ...   \n",
              "439  0.0  0.999958  0.0  0.0  3.000026  0.0  1.999997  0.0  11.000018   \n",
              "440  0.0  2.999955  0.0  0.0  2.000013  0.0  1.999998  0.0   9.000010   \n",
              "441  0.0  0.999984  0.0  0.0  0.999946  0.0  0.999998  0.0   3.999985   \n",
              "442  0.0  2.999944  0.0  0.0  3.000010  0.0  2.999996  0.0  12.000012   \n",
              "443  0.0  1.999948  0.0  0.0  1.000012  0.0  0.999997  0.0   5.000008   \n",
              "\n",
              "           9    10  \n",
              "0    2.993027  0.0  \n",
              "1    0.988105  0.0  \n",
              "2    0.992845  0.0  \n",
              "3    2.033132  0.0  \n",
              "4    2.005602  0.0  \n",
              "..        ...  ...  \n",
              "439  3.002066  0.0  \n",
              "440  2.001895  0.0  \n",
              "441  1.000429  0.0  \n",
              "442  3.001447  0.0  \n",
              "443  0.995217  0.0  \n",
              "\n",
              "[444 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e0e22e7-36dc-4518-ad60-a2270a7d3fb9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.999975</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.999971</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.999995</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.000001</td>\n",
              "      <td>2.993027</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.999948</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000023</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.999994</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.000013</td>\n",
              "      <td>0.988105</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.999930</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000061</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.999996</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.000026</td>\n",
              "      <td>0.992845</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.999974</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.999988</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000005</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.033132</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.999969</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.000021</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.999999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000015</td>\n",
              "      <td>2.005602</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.999958</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.000026</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.999997</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.000018</td>\n",
              "      <td>3.002066</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.999955</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000013</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.999998</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.000010</td>\n",
              "      <td>2.001895</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.999984</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.999946</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.999998</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.999985</td>\n",
              "      <td>1.000429</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>442</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.999944</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.000010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.999996</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.000012</td>\n",
              "      <td>3.001447</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.999948</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000012</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.999997</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.000008</td>\n",
              "      <td>0.995217</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>444 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e0e22e7-36dc-4518-ad60-a2270a7d3fb9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e0e22e7-36dc-4518-ad60-a2270a7d3fb9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e0e22e7-36dc-4518-ad60-a2270a7d3fb9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    }
  ]
}